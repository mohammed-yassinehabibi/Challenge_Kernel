{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import py_stringmatching as sm\n",
    "import osqp\n",
    "from collections import Counter\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "from Local_packages.kernels import compute_kernel_matrix, gaussian_kernel, normalize\n",
    "from Local_packages.run import KernelMethod\n",
    "from Local_packages.optimizer import KLR_solver, SVM_solver\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "Xtr0 = pd.read_csv('data/Xtr0.csv', index_col=0)\n",
    "Xtr1 = pd.read_csv('data/Xtr1.csv', index_col=0)\n",
    "Xtr2 = pd.read_csv('data/Xtr2.csv',  index_col=0)\n",
    "Xte0 = pd.read_csv('data/Xte0.csv', index_col=0)\n",
    "Xte1 = pd.read_csv('data/Xte1.csv', index_col=0)\n",
    "Xte2 = pd.read_csv('data/Xte2.csv', index_col=0)\n",
    "\n",
    "Xtr0_Xte0 = pd.concat([Xtr0, Xte0], ignore_index=True)\n",
    "Xtr1_Xte1 = pd.concat([Xtr1, Xte1], ignore_index=True)\n",
    "Xtr2_Xte2 = pd.concat([Xtr2, Xte2], ignore_index=True)\n",
    "\n",
    "# Load the labels\n",
    "Ytr0 = pd.read_csv('data/Ytr0.csv', index_col=0)\n",
    "Ytr1 = pd.read_csv('data/Ytr1.csv', index_col=0)\n",
    "Ytr2 = pd.read_csv('data/Ytr2.csv', index_col=0)\n",
    "# Convert the labels to -1, 1\n",
    "Ytr0 = 2*Ytr0['Bound'].values - 1\n",
    "Ytr1 = 2*Ytr1['Bound'].values - 1\n",
    "Ytr2 = 2*Ytr2['Bound'].values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrix representation of the sequences\n",
    "Xtr0_mat100 = pd.read_csv('data/Xtr0_mat100.csv', header=None, sep=' ').values\n",
    "Xtr1_mat100 = pd.read_csv('data/Xtr1_mat100.csv', header=None, sep=' ').values\n",
    "Xtr2_mat100 = pd.read_csv('data/Xtr2_mat100.csv', header=None, sep=' ').values\n",
    "Xte0_mat100 = pd.read_csv('data/Xte0_mat100.csv', header=None, sep=' ').values\n",
    "Xte1_mat100 = pd.read_csv('data/Xte1_mat100.csv', header=None, sep=' ').values\n",
    "Xte2_mat100 = pd.read_csv('data/Xte2_mat100.csv', header=None, sep=' ').values\n",
    "\n",
    "Xtr0_Xte0_mat100 = np.concatenate([Xtr0_mat100, Xte0_mat100], axis=0)\n",
    "Xtr1_Xte1_mat100 = np.concatenate([Xtr1_mat100, Xte1_mat100], axis=0)\n",
    "Xtr2_Xte2_mat100 = np.concatenate([Xtr2_mat100, Xte2_mat100], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Compute Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product\n",
    "\n",
    "def gkm_kernel(seq1, seq2, k=3, gap=1):\n",
    "    \"\"\"Compute the gapped k-mer kernel between two sequences.\"\"\"\n",
    "    def extract_gapped_kmers(seq, k, gap):\n",
    "        kmers = set()\n",
    "        for i in range(len(seq) - (k + gap - 1)):\n",
    "            kmers.add(seq[i] + seq[i + gap + 1 : i + gap + k])  # gapped k-mer\n",
    "        return kmers\n",
    "    \n",
    "    kmers1 = extract_gapped_kmers(seq1, k, gap)\n",
    "    kmers2 = extract_gapped_kmers(seq2, k, gap)\n",
    "    \n",
    "    return len(kmers1.intersection(kmers2))  # Kernel similarity score\n",
    "\n",
    "def compute_row(i, X_left, X_right, k, gap):\n",
    "    \"\"\"Compute one row of the kernel matrix.\"\"\"\n",
    "    return [gkm_kernel(X_left[i], X_right[j], k, gap) for j in range(len(X_right))]\n",
    "\n",
    "def compute_gkm_kernel_matrix(X_left, X_right, k=3, gap=1, n_jobs=-1):\n",
    "    \"\"\"Compute the gapped k-mer kernel matrix using parallelization.\"\"\"\n",
    "    n_samples_left = len(X_left)\n",
    "    \n",
    "    kernel_matrix = Parallel(n_jobs=n_jobs)(\n",
    "      delayed(compute_row)(i, X_left, X_right, k, gap) for i in tqdm(range(n_samples_left))\n",
    "    )\n",
    "    \n",
    "    return np.array(kernel_matrix)\n",
    "\n",
    "# Example usage\n",
    "X_left = Xtr0_Xte0['seq'].to_list()\n",
    "X_right = Xtr0_Xte0['seq'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:42<00:00, 71.11it/s]\n",
      "100%|██████████| 3000/3000 [00:45<00:00, 65.77it/s]\n",
      "100%|██████████| 3000/3000 [00:48<00:00, 62.21it/s]\n"
     ]
    }
   ],
   "source": [
    "kernel_matrix_0 = compute_gkm_kernel_matrix(Xtr0_Xte0['seq'].to_list(), Xtr0_Xte0['seq'].to_list(), k=8, gap=5)\n",
    "K_0 = normalize(kernel_matrix_0)\n",
    "kernel_matrix_1 = compute_gkm_kernel_matrix(Xtr1_Xte1['seq'].to_list(), Xtr1_Xte1['seq'].to_list(), k=8, gap=5)\n",
    "K_1 = normalize(kernel_matrix_1)\n",
    "kernel_matrix_2 = compute_gkm_kernel_matrix(Xtr2_Xte2['seq'].to_list(), Xtr2_Xte2['seq'].to_list(), k=8, gap=5)\n",
    "K_2 = normalize(kernel_matrix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'mis_sub'\n",
    "\n",
    "#Gaussian Kernel - On the matrix representation of the sequences\n",
    "if kernel=='exp':\n",
    "    args = {'sigma': 0.13}\n",
    "#Smith-Waterman Local Alignment Score\n",
    "elif kernel=='sw':\n",
    "    args = {'sw': sm.SmithWaterman()}\n",
    "#Spectrum Kernel\n",
    "elif kernel=='spect':\n",
    "    args = {'k': 5}\n",
    "#Mismatch Kernel\n",
    "elif kernel=='mismatch':\n",
    "    args = {'k': 10, 'm': 2}\n",
    "elif kernel=='mis_sub':\n",
    "    args = {'k': 10, 'm': 2}\n",
    "#LA Kernel\n",
    "elif kernel=='LA':\n",
    "    args = {'beta': 0.5, 'd': 11, 'e': 1}\n",
    "elif kernel=='LA_gpu':\n",
    "    args = {'beta': 0.5, 'd': 1, 'e': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_0 = compute_kernel_matrix(Xtr0, Xtr0, kernel, **args)\n",
    "K_1 = compute_kernel_matrix(Xtr1, Xte1, kernel, **args)\n",
    "K_2 = compute_kernel_matrix(Xtr2, Xte2, kernel, **args)\n",
    "\n",
    "#K_0 = compute_kernel_matrix(Xtr0_Xte0, Xtr0_Xte0, kernel, **args)\n",
    "#K_1 = compute_kernel_matrix(Xtr1_Xte1, Xtr1_Xte1, kernel, **args)\n",
    "#K_2 = compute_kernel_matrix(Xtr2_Xte2, Xtr2_Xte2, kernel, **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('features/K_0_tr_mismatch_10-2.npy', K_0)\n",
    "np.save('features/K_1_te_mismatch_10-2.npy', K_1.T)\n",
    "np.save('features/K_2_te_mismatch_10-2.npy', K_2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute only the diagonal of the kernel matrix for the test set\n",
    "def compute_kernel_for_row(i, Xte, kernel, args):\n",
    "    return compute_kernel_matrix(Xte.iloc[[i]], Xte.iloc[[i]], kernel, **args)\n",
    "\n",
    "#K_te_0 = np.concatenate(Parallel(n_jobs=-1)(delayed(compute_kernel_for_row)(i, Xte0, kernel, args) for i in tqdm(range(len(Xte0)))), axis=0)\n",
    "K_te_1 = np.concatenate(Parallel(n_jobs=-1)(delayed(compute_kernel_for_row)(i, Xte1, kernel, args) for i in tqdm(range(len(Xte1)))), axis=0)\n",
    "K_te_2 = np.concatenate(Parallel(n_jobs=-1)(delayed(compute_kernel_for_row)(i, Xte2, kernel, args) for i in tqdm(range(len(Xte2)))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('features/K_0_tr_mismatch_10-2.npy', K_0)\n",
    "np.save('features/K_1_te_diag_mismatch_10-2.npy', K_te_1)\n",
    "np.save('features/K_2_te_diag_mismatch_10-2.npy', K_te_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Merge sub-kernels into one kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the kernel matrices on Xtr x Xtr\n",
    "K_tr_0 = np.load('features/K_0_tr_mismatch_10-2.npy')\n",
    "K_tr_1 = np.load('features/K_1_tr_mismatch_10-2.npy')\n",
    "K_tr_2 = np.load('features/K_2_tr_mismatch_10-2.npy')\n",
    "# Load the kernel vector on {Xte_i, Xte_i}_i\n",
    "K_te_0 = np.load('features/K_0_te_diag_mismatch_10-2.npy')\n",
    "K_te_1 = np.load('features/K_1_te_diag_mismatch_10-2.npy')\n",
    "K_te_2 = np.load('features/K_2_te_diag_mismatch_10-2.npy')\n",
    "# Concatenate the kernel vector on {Xtr_i, Xte_i}_i and {Xte_i, Xte_i}_i to get the diagonal of the whole kernel matrix K \n",
    "K_diag_0 = np.concatenate([np.diag(K_tr_0),K_te_0.flatten()], axis=0)\n",
    "K_diag_1 = np.concatenate([np.diag(K_tr_1),K_te_1.flatten()], axis=0)\n",
    "K_diag_2 = np.concatenate([np.diag(K_tr_2),K_te_2.flatten()], axis=0)\n",
    "# Load the kernel matrices on Xte x Xtr\n",
    "K_tr_te_0 = np.load('features/K_0_te_mismatch_10-2.npy')\n",
    "K_tr_te_1 = np.load('features/K_1_te_mismatch_10-2.npy')\n",
    "K_tr_te_2 = np.load('features/K_2_te_mismatch_10-2.npy')\n",
    "# Concatenate the kernel matrices on Xtr x Xtr and Xte x Xtr to get the whole kernel matrix K on (Xtr U Xte) x Xtr\n",
    "K_0 = np.concatenate([K_tr_0, K_tr_te_0], axis=0)\n",
    "K_1 = np.concatenate([K_tr_1, K_tr_te_1], axis=0)\n",
    "K_2 = np.concatenate([K_tr_2, K_tr_te_2], axis=0)\n",
    "# Normalize the kernel matrix K\n",
    "D_0 = np.diag(1/np.sqrt(K_diag_0))\n",
    "D_1 = np.diag(1/np.sqrt(K_diag_1))\n",
    "D_2 = np.diag(1/np.sqrt(K_diag_2))\n",
    "K_0 = np.dot(np.dot(D_0, K_0), D_0[:K_tr_0.shape[0]][:,:K_tr_0.shape[0]]) \n",
    "K_1 = np.dot(np.dot(D_1, K_1), D_1[:K_tr_0.shape[0]][:,:K_tr_0.shape[0]]) \n",
    "K_2 = np.dot(np.dot(D_2, K_2), D_2[:K_tr_0.shape[0]][:,:K_tr_0.shape[0]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('features/K_0_mismatch_10-2.npy', K_0)\n",
    "np.save('features/K_1_mismatch_10-2.npy', K_1)\n",
    "np.save('features/K_2_mismatch_10-2.npy', K_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Load kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_versions = ['5-1', '5-2', '6-1', '6-2', '7-1', '7-2', '8-1', '8-2', '9-1', '9-2', '10-2']\n",
    "K_0_dict, K_1_dict, K_2_dict = {}, {}, {}\n",
    "\n",
    "for version in kernel_versions:\n",
    "    K_0_dict[version] = np.load(f'features/K_0_mismatch_{version}.npy')\n",
    "    K_1_dict[version] = np.load(f'features/K_1_mismatch_{version}.npy')\n",
    "    K_2_dict[version] = np.load(f'features/K_2_mismatch_{version}.npy')\n",
    "\n",
    "# Load the additional kernel matrix\n",
    "#K_0_dict['exp-0_1'] = np.load('features/K_0_exp-0_1.npy')\n",
    "#K_1_dict['exp-0_1'] = np.load('features/K_1_exp-0_1.npy')\n",
    "#K_2_dict['exp-0_1'] = np.load('features/K_2_exp-0_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50571245 0.68502593 0.454753 0.5665562 0.4964234\n",
      "0.006316263 0.045187116 0.0 0.034760356 0.0020040865\n"
     ]
    }
   ],
   "source": [
    "print(K_0_dict['8-1'][1:,0].max(), K_0_dict['8-2'][1:,0].max(), K_0_dict['9-1'][1:,0].max(), K_0_dict['9-2'][1:,0].max(), K_0_dict['10-2'][1:,0].max())\n",
    "print(K_0_dict['8-1'][1:,0].min(), K_1_dict['8-2'][1:,0].min(), K_1_dict['9-1'][1:,0].min(), K_0_dict['9-2'][1:,0].min(), K_1_dict['10-2'][1:,0].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Combine kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_versions = ['9-2', '10-2']\n",
    "K_0_prod_2 = np.prod([K_0_dict[version][:,:2000] for version in kernel_versions], axis=0)\n",
    "K_1_prod_2 = np.prod([K_1_dict[version][:,:2000] for version in kernel_versions], axis=0)\n",
    "K_2_prod_2 = np.prod([K_2_dict[version][:,:2000] for version in kernel_versions], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exponential kernel from concatenation of kernels\n",
    "#Concatenate Kernels\n",
    "kernel_versions = ['5-2', '6-2', '9-2', '8-2']\n",
    "K_0_concat = np.stack([K_0_dict[version][:, :2000] for version in kernel_versions], axis=-1)\n",
    "K_1_concat = np.stack([K_1_dict[version][:, :2000] for version in kernel_versions], axis=-1)\n",
    "K_2_concat = np.stack([K_2_dict[version][:, :2000] for version in kernel_versions], axis=-1)\n",
    "#Take norm Kernel\n",
    "K_0_exp = np.exp(np.linalg.norm(K_0_concat, axis=-1))\n",
    "K_1_exp = np.exp(np.linalg.norm(K_1_concat, axis=-1))\n",
    "K_2_exp = np.exp(np.linalg.norm(K_2_concat, axis=-1))\n",
    "K_0_norm = np.linalg.norm(K_0_concat, axis=-1)\n",
    "K_1_norm = np.linalg.norm(K_1_concat, axis=-1)\n",
    "K_2_norm = np.linalg.norm(K_2_concat, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal kernel (gives 100% accuracy on the training set)\n",
    "K_0_opt = ((Ytr0+1)/2)[:,None]*((Ytr0+1)/2)[None,:]\n",
    "K_1_opt = ((Ytr1+1)/2)[:,None]*((Ytr1+1)/2)[None,:]\n",
    "K_2_opt = ((Ytr2+1)/2)[:,None]*((Ytr2+1)/2)[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment(K_a, K_a_opt):\n",
    "    return np.sum(K_a[:2000]*K_a_opt)/np.sqrt(np.sum(K_a[:2000]**2)*np.sum(K_a_opt**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_versions = ['5-1', '5-2', '6-1', '6-2', '7-1', '7-2', '8-1', '8-2', '9-1', '9-2']\n",
    "for kernel_version in kernel_versions:\n",
    "    print(alignment(K_2_dict[kernel_version][:,:2000],K_2_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dataset 0\n",
    "w_0_prod_1 = alignment(K_0_prod_1, K_0_opt)\n",
    "w_0_prod_2 = alignment(K_0_prod_2, K_0_opt)\n",
    "w_0 = w_0_prod_1 + w_0_prod_2\n",
    "K_0 = K_0_prod_1**(w_0_prod_1/w_0)*K_0_prod_2**(w_0_prod_2/w_0) + 1\n",
    "\n",
    "# For dataset 1\n",
    "w_1_prod_1 = alignment(K_1_prod_1, K_1_opt)\n",
    "w_1_prod_2 = alignment(K_1_prod_2, K_1_opt)\n",
    "w_1 = w_1_prod_1 + w_1_prod_2\n",
    "K_1 = K_1_prod_1**(w_1_prod_1/w_1)*K_1_prod_2**(w_1_prod_2/w_1) + 1\n",
    "\n",
    "# For dataset 2\n",
    "w_2_prod_1 = alignment(K_2_prod_1, K_2_opt)\n",
    "w_2_prod_2 = alignment(K_2_prod_2, K_2_opt)\n",
    "w_2 = w_2_prod_1 + w_2_prod_2\n",
    "K_2 = K_2_prod_1**(w_2_prod_1/w_2)*K_2_prod_2**(w_2_prod_2/w_2) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Local Alignment Kernel  : <span style=\"color:green\">TODO / Time Complexity too high + value too high</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Local Alignment Kernel defined as:\n",
    "$$K_{LA}^{(\\beta)}(x,y) = \\sum_{\\pi\\in\\Pi(x,y)} s_{S,g}(\\pi)$$\n",
    "\n",
    "is symmetric positive definite.\n",
    "\n",
    "We assume an affine gap penalty:\n",
    "$$\\left\\{\\begin{aligned}\n",
    "&g(0) = 0 \\\\\n",
    "&g(n) = d + e(n-1) \\quad \\text{for } n>0\n",
    "\\end{aligned}\\right.$$\n",
    "\n",
    "where $l(\\pi)$ is the length of the alignment $\\pi$.\n",
    "\n",
    "We use the formula for the Local Alignment Kernel:\n",
    "$$K_{LA}^{(\\beta)}(x,y) = 1 + X_2(|x|,|y|)+ Y_2(|x|,|y|) + M(|x|,|y|)$$ \n",
    "where $X_2$, $Y_2$ and $M$ are defined recursively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Run Kernel Method on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "solver=SVM_solver #quad_solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Dataset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9927777777777778, 0.605)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_0_concat = np.stack([K_0_dict[version][:, :2000] for version in ['8-2', '9-2', '5-1']], axis=-1)\n",
    "K_0_norm = np.linalg.norm(K_0_concat, axis=-1)\n",
    "K_0 = K_0_norm+1\n",
    "\n",
    "#Method\n",
    "lambd = 1e-4\n",
    "method_0 = KernelMethod(K_0[:2000, :2000], Ytr0, solver=SVM_solver)\n",
    "method_0.lambd = lambd\n",
    "method_0.train_test_split(test_size=0.1, random_state=12)\n",
    "method_0.fit()\n",
    "method_0.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 11/11 [00:24<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9905263157894737, 0.63)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "methods = {}\n",
    "lambd = 5e-5\n",
    "\n",
    "for version, K in tqdm(K_0_dict.items(), desc='Training'):\n",
    "    K_0 = K[:, :2000] + 1\n",
    "    method = KernelMethod(K_0[:2000, :2000], Ytr0, solver=SVM_solver)\n",
    "    method.lambd = lambd\n",
    "    method.train_test_split(test_size=0.05, random_state=4)\n",
    "    method.fit()\n",
    "    method.evaluate()\n",
    "    methods[version] = method\n",
    "\n",
    "# Example to access a method\n",
    "print(methods['8-2'].evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(models):\n",
    "    m_train = np.array([np.dot(model.kernel[model.train_indices][:, model.train_indices], model.alpha) for model in models])\n",
    "    m_train_sgn = np.sign(m_train)\n",
    "    m_train_agg = np.sign(np.mean(m_train_sgn, axis=0))\n",
    "    train_accuracy = np.mean(m_train_agg == models[0].Y[models[0].train_indices])\n",
    "\n",
    "    m_test = np.array([np.dot(model.kernel[model.test_indices][:, model.train_indices], model.alpha) for model in models])\n",
    "    m_test_sgn = np.sign(m_test)\n",
    "    m_test_agg = np.sign(np.mean(m_test_sgn, axis=0))\n",
    "    test_accuracy = np.mean(m_test_agg == models[0].Y[models[0].test_indices])\n",
    "    return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9905263157894737, 0.65)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate([method for method in methods.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "method_0.grid_search(np.logspace(-5, -3, 10), test_size=0.1, n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for pow\n",
    "pow_values = np.linspace(0.01, 0.1, 3)\n",
    "\n",
    "# Perform grid search\n",
    "best_pow = None\n",
    "best_accuracy = -np.inf\n",
    "\n",
    "for pow in pow_values:\n",
    "    method_0 = KernelMethod((K_0_exp**pow)[:2000][:, :2000], Ytr0, lambd=lambd, solver=SVM_solver)\n",
    "    method_0.train_test_split(test_size=0.1)\n",
    "    accuracy = method_0.validate(test_size=0.1, n_splits=10)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_pow = pow\n",
    "\n",
    "print(f\"Best pow: {best_pow}\")\n",
    "print(f\"Best average accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.636\n",
      "Min Accuracy: 0.58 Max Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_0.validate(test_size=0.1, n_splits=20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BEST AVERAGE ACCURACY : 64.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_0_concat = np.stack([K_0_dict[version][:, :2000] for version in ['8-2', '9-2', '5-1']], axis=-1)\n",
    "K_0_norm = np.linalg.norm(K_0_concat, axis=-1)\n",
    "K_0 = K_0_norm+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_1 = K_1_dict['9-2'][:,:2000]**2 # lambd_2 = 1e-4 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.3241900e-08, -6.9865045e-08, -6.3039266e-08, ...,\n",
       "        9.1719751e+00,  1.2920563e+01,  3.6662365e+01], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvalsh(K_1[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR in LDL_factor: Error in KKT matrix LDL factorization when computing the nonzero elements. The problem seems to be non-convex\n",
      "ERROR in osqp_setup: KKT matrix factorization.\n",
      "The problem seems to be non-convex.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Workspace allocation error!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m method_1 \u001b[38;5;241m=\u001b[39m KernelMethod((K_1)[:\u001b[38;5;241m2000\u001b[39m], Ytr1, lambd\u001b[38;5;241m=\u001b[39mlambd_1, solver\u001b[38;5;241m=\u001b[39mSVM_solver)\n\u001b[0;32m      4\u001b[0m method_1\u001b[38;5;241m.\u001b[39mtrain_test_split(test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmethod_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m method_1\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[1;32mc:\\Users\\habib\\Documents\\Mohammed-Yassine\\2024_2025\\MVA\\P2\\Kernel Methods\\Challenge_Kernel\\Local_packages\\run.py:79\u001b[0m, in \u001b[0;36mKernelMethod.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Solve for alpha and bias together\u001b[39;00m\n\u001b[0;32m     78\u001b[0m Y_aug \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(Y_train, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Augmented Y vector\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_aug \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlambd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Extract alpha and bias\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_aug[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\habib\\Documents\\Mohammed-Yassine\\2024_2025\\MVA\\P2\\Kernel Methods\\Challenge_Kernel\\Local_packages\\optimizer.py:214\u001b[0m, in \u001b[0;36mSVM_solver\u001b[1;34m(K, Y, lambd, is_2_svm)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     K_sparse \u001b[38;5;241m=\u001b[39m csc_matrix(K)\n\u001b[1;32m--> 214\u001b[0m     \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcsc_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlambd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m results \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39msolve()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[1;32mc:\\Users\\habib\\anaconda3\\envs\\general_env\\Lib\\site-packages\\osqp\\interface.py:37\u001b[0m, in \u001b[0;36mOSQP.setup\u001b[1;34m(self, P, q, A, l, u, **settings)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_derivative_cache \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m'\u001b[39m: P, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m: q, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m: A, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m'\u001b[39m: l, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m: u}\n\u001b[0;32m     36\u001b[0m unpacked_data, settings \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mprepare_data(P, q, A, l, u, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Workspace allocation error!"
     ]
    }
   ],
   "source": [
    "lambd_1 = 1e-2\n",
    "\n",
    "method_1 = KernelMethod((K_1)[:2000], Ytr1, lambd=lambd_1, solver=SVM_solver)\n",
    "method_1.train_test_split(test_size=0.2)\n",
    "method_1.fit()\n",
    "method_1.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03125,  0.03125, -0.03125, ..., -0.03125,  0.03125, -0.03125])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_1.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.abs(method_1.alpha)>1e-3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search for lambda\n",
    "method_1.grid_search(np.logspace(-9, -7, 10), test_size=0.25, n_folds=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for pow\n",
    "pow_values = np.linspace(0.5, 2, 5)\n",
    "\n",
    "# Perform grid search\n",
    "best_pow = None\n",
    "best_accuracy = -np.inf\n",
    "\n",
    "for pow in pow_values:\n",
    "    method_2 = KernelMethod(((K_1_exp-1)**pow+1)[:2000][:, :2000], Ytr1, lambd=lambd_1, solver=SVM_solver)\n",
    "    method_2.train_test_split(test_size=0.1)\n",
    "    accuracy = method_2.validate(test_size=0.1, n_splits=10)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_pow = pow\n",
    "\n",
    "print(f\"Best pow: {best_pow}\")\n",
    "print(f\"Best average accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.751\n",
      "Min Accuracy: 0.705 Max Accuracy: 0.815\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_1.validate(test_size=0.1, n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BEST AVERAGE ACCURACY : 79.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.7905\n",
      "Min Accuracy: 0.755 Max Accuracy: 0.815\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_1.validate(test_size=0.1, n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = K_2_dict['9-1'][:,:2000]*K_2_dict['9-2'][:,:2000]**2+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.75)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambd_2 = 2e-4\n",
    "\n",
    "method_2 = KernelMethod((test)[:2000][:, :2000], Ytr2, lambd=lambd_2, solver=SVM_solver)\n",
    "method_2.train_test_split(test_size=0.05)\n",
    "method_2.fit()\n",
    "method_2.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "method_2.grid_search(np.logspace(-5, -3.5, 8), test_size=0.1, n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for pow\n",
    "pow_values = np.linspace(0.5, 3, 10)\n",
    "\n",
    "# Perform grid search\n",
    "best_pow = None\n",
    "best_accuracy = -np.inf\n",
    "\n",
    "for pow in pow_values:\n",
    "    method_2 = KernelMethod((K_2**pow)[:2000][:, :2000], Ytr2, lambd=lambd_2, solver=SVM_solver)\n",
    "    method_2.train_test_split(test_size=0.1)\n",
    "    accuracy = method_2.validate(test_size=0.1, n_splits=20)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_pow = pow\n",
    "\n",
    "print(f\"Best pow: {best_pow}\")\n",
    "print(f\"Best average accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.6895\n",
      "Min Accuracy: 0.63 Max Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_2.validate(test_size=0.05, n_splits=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BEST AVERAGE ACCURACY : 69.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.69575\n",
      "Min Accuracy: 0.64 Max Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "test = K_2_dict['9-1'][:,:2000]*K_2_dict['9-2'][:,:2000]**2+1 # lambd_2 = 1e-4 ?\n",
    "average_accuracy = method_2.validate(test_size=0.1, n_splits=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Apply Kernel Predictor on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_labels(K, method):\n",
    "    K_te = K\n",
    "    alpha = method.alpha\n",
    "    # Predictions\n",
    "    Yte0 = np.sign(K_te @ alpha)\n",
    "    return Yte0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte_file_name = 'Yte_mismatch_exp_8_9_5.csv'\n",
    "\n",
    "#Yte0 = predict_test_labels(K_0[2000:][:, method_0.train_indices], method_0)\n",
    "#Yte1 = predict_test_labels(K_1[2000:][:,method_1.train_indices], method_1)\n",
    "Yte2 = predict_test_labels(test[2000:][:,method_2.train_indices], method_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte = pd.read_csv('Yte_mismatch_9_10.csv', index_col=0)\n",
    "Yte0 = Yte['Bound'].values[:1000]*2-1\n",
    "Yte1 = Yte['Bound'].values[1000:2000]*2-1\n",
    "Yte2 = Yte['Bound'].values[2000:]*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte_file_name = 'Yte_mismatch_9_10_bias_1.csv'\n",
    "\n",
    "# Concatenate and add Id column\n",
    "Yte = np.concatenate([Yte0, Yte1, Yte2])\n",
    "Yte = pd.DataFrame(data=(Yte + 1) // 2, columns=['Bound'], dtype='int64')\n",
    "Yte.insert(0, 'Id', Yte.index)\n",
    "\n",
    "# Save the predictions\n",
    "Yte.to_csv(Yte_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
