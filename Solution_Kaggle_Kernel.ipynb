{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import py_stringmatching as sm\n",
    "import osqp\n",
    "from collections import Counter\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "from Local_packages.kernels import compute_kernel_matrix, gaussian_kernel, normalize\n",
    "from Local_packages.run import KernelMethod\n",
    "from Local_packages.optimizer import KLR_solver, SVM_solver\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "Xtr0 = pd.read_csv('data/Xtr0.csv', index_col=0)\n",
    "Xtr1 = pd.read_csv('data/Xtr1.csv', index_col=0)\n",
    "Xtr2 = pd.read_csv('data/Xtr2.csv',  index_col=0)\n",
    "Xte0 = pd.read_csv('data/Xte0.csv', index_col=0)\n",
    "Xte1 = pd.read_csv('data/Xte1.csv', index_col=0)\n",
    "Xte2 = pd.read_csv('data/Xte2.csv', index_col=0)\n",
    "\n",
    "Xtr0_Xte0 = pd.concat([Xtr0, Xte0], ignore_index=True)\n",
    "Xtr1_Xte1 = pd.concat([Xtr1, Xte1], ignore_index=True)\n",
    "Xtr2_Xte2 = pd.concat([Xtr2, Xte2], ignore_index=True)\n",
    "\n",
    "# Load the labels\n",
    "Ytr0 = pd.read_csv('data/Ytr0.csv', index_col=0)\n",
    "Ytr1 = pd.read_csv('data/Ytr1.csv', index_col=0)\n",
    "Ytr2 = pd.read_csv('data/Ytr2.csv', index_col=0)\n",
    "# Convert the labels to -1, 1\n",
    "Ytr0 = 2*Ytr0['Bound'].values - 1\n",
    "Ytr1 = 2*Ytr1['Bound'].values - 1\n",
    "Ytr2 = 2*Ytr2['Bound'].values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrix representation of the sequences\n",
    "Xtr0_mat100 = pd.read_csv('data/Xtr0_mat100.csv', header=None, sep=' ').values\n",
    "Xtr1_mat100 = pd.read_csv('data/Xtr1_mat100.csv', header=None, sep=' ').values\n",
    "Xtr2_mat100 = pd.read_csv('data/Xtr2_mat100.csv', header=None, sep=' ').values\n",
    "Xte0_mat100 = pd.read_csv('data/Xte0_mat100.csv', header=None, sep=' ').values\n",
    "Xte1_mat100 = pd.read_csv('data/Xte1_mat100.csv', header=None, sep=' ').values\n",
    "Xte2_mat100 = pd.read_csv('data/Xte2_mat100.csv', header=None, sep=' ').values\n",
    "\n",
    "Xtr0_Xte0_mat100 = np.concatenate([Xtr0_mat100, Xte0_mat100], axis=0)\n",
    "Xtr1_Xte1_mat100 = np.concatenate([Xtr1_mat100, Xte1_mat100], axis=0)\n",
    "Xtr2_Xte2_mat100 = np.concatenate([Xtr2_mat100, Xte2_mat100], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Compute Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'mismatch'\n",
    "\n",
    "#Gaussian Kernel - On the matrix representation of the sequences\n",
    "if kernel=='exp':\n",
    "    args = {'sigma': 1}\n",
    "#Smith-Waterman Local Alignment Score\n",
    "elif kernel=='sw':\n",
    "    args = {'sw': sm.SmithWaterman()}\n",
    "#Spectrum Kernel\n",
    "elif kernel=='spect':\n",
    "    args = {'k': 5}\n",
    "#Mismatch Kernel\n",
    "elif kernel=='mismatch':\n",
    "    args = {'k': 9, 'm': 1}\n",
    "elif kernel=='mis_sub':\n",
    "    args = {'k': 9, 'm': 2}\n",
    "#LA Kernel\n",
    "elif kernel=='LA':\n",
    "    args = {'beta': 0.5, 'd': 11, 'e': 1}\n",
    "elif kernel=='LA_gpu':\n",
    "    args = {'beta': 0.5, 'd': 1, 'e': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature vectors: 100%|██████████| 3000/3000 [00:04<00:00, 686.81it/s]\n",
      "Collecting k-mers: 100%|██████████| 3000/3000 [00:17<00:00, 170.71it/s]\n",
      "Building sparse matrix entries: 100%|██████████| 3000/3000 [06:16<00:00,  7.98it/s]\n",
      "Computing feature vectors: 100%|██████████| 3000/3000 [00:04<00:00, 630.40it/s]\n",
      "Collecting k-mers: 100%|██████████| 3000/3000 [00:16<00:00, 183.99it/s]\n",
      "Building sparse matrix entries: 100%|██████████| 3000/3000 [04:45<00:00, 10.49it/s]\n",
      "Computing feature vectors: 100%|██████████| 3000/3000 [00:03<00:00, 765.72it/s]\n",
      "Collecting k-mers: 100%|██████████| 3000/3000 [00:17<00:00, 171.34it/s]\n",
      "Building sparse matrix entries: 100%|██████████| 3000/3000 [05:01<00:00,  9.94it/s]\n"
     ]
    }
   ],
   "source": [
    "#K_exp_0 = compute_kernel_matrix(Xtr0_mat100, Xtr0_mat100, kernel, **args)\n",
    "#K_exp_1 = compute_kernel_matrix(Xtr1_mat100, Xtr1_mat100, kernel, **args)\n",
    "#K_exp_2 = compute_kernel_matrix(Xtr2_mat100, Xtr2_mat100, kernel, **args)\n",
    "\n",
    "K_0 = compute_kernel_matrix(Xtr0_Xte0, Xtr0_Xte0, kernel, **args)\n",
    "K_1 = compute_kernel_matrix(Xtr1_Xte1, Xtr1_Xte1, kernel, **args)\n",
    "K_2 = compute_kernel_matrix(Xtr2_Xte2, Xtr2_Xte2, kernel, **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('features/K_0_mismatch_9-1.npy', K_0)\n",
    "np.save('features/K_1_mismatch_9-1.npy', K_1)\n",
    "np.save('features/K_2_mismatch_9-1.npy', K_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel_for_row(i, Xte, kernel, args):\n",
    "    return compute_kernel_matrix(Xte.iloc[[i]], Xte.iloc[[i]], kernel, **args)\n",
    "\n",
    "K_te_0 = np.concatenate(Parallel(n_jobs=-1)(delayed(compute_kernel_for_row)(i, Xte0, kernel, args) for i in tqdm(range(len(Xte0)))), axis=0)\n",
    "K_te_1 = np.concatenate(Parallel(n_jobs=-1)(delayed(compute_kernel_for_row)(i, Xte1, kernel, args) for i in tqdm(range(len(Xte1)))), axis=0)\n",
    "K_te_2 = np.concatenate(Parallel(n_jobs=-1)(delayed(compute_kernel_for_row)(i, Xte2, kernel, args) for i in tqdm(range(len(Xte2)))), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Load kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the kernel matrices on Xtr x Xtr\n",
    "K_tr_0 = np.load('features/K_0_tr_mismatch_9-2.npy')\n",
    "K_tr_1 = np.load('features/K_1_tr_mismatch_9-2.npy')\n",
    "K_tr_2 = np.load('features/K_2_tr_mismatch_9-2.npy')\n",
    "# Load the kernel vector on {Xte_i, Xte_i}_i\n",
    "K_te_0 = np.load('features/K_0_te_diag_mismatch_9-2.npy')\n",
    "K_te_1 = np.load('features/K_1_te_diag_mismatch_9-2.npy')\n",
    "K_te_2 = np.load('features/K_2_te_diag_mismatch_9-2.npy')\n",
    "# Concatenate the kernel vector on {Xtr_i, Xte_i}_i and {Xte_i, Xte_i}_i to get the diagonal of the whole kernel matrix K \n",
    "K_diag_0 = np.concatenate([np.diag(K_tr_0),K_te_0.flatten()], axis=0)\n",
    "K_diag_1 = np.concatenate([np.diag(K_tr_1),K_te_1.flatten()], axis=0)\n",
    "K_diag_2 = np.concatenate([np.diag(K_tr_2),K_te_2.flatten()], axis=0)\n",
    "# Load the kernel matrices on Xte x Xtr\n",
    "K_tr_te_0 = np.load('features/K_0_te_mismatch_9-2.npy')\n",
    "K_tr_te_1 = np.load('features/K_1_te_mismatch_9-2.npy')\n",
    "K_tr_te_2 = np.load('features/K_2_te_mismatch_9-2.npy')\n",
    "# Concatenate the kernel matrices on Xtr x Xtr and Xte x Xtr to get the whole kernel matrix K on (Xtr U Xte) x Xtr\n",
    "K_0 = np.concatenate([K_tr_0, K_tr_te_0], axis=0)\n",
    "K_1 = np.concatenate([K_tr_1, K_tr_te_1], axis=0)\n",
    "K_2 = np.concatenate([K_tr_2, K_tr_te_2], axis=0)\n",
    "# Normalize the kernel matrix K\n",
    "D_0 = np.diag(1/np.sqrt(K_diag_0))\n",
    "D_1 = np.diag(1/np.sqrt(K_diag_1))\n",
    "D_2 = np.diag(1/np.sqrt(K_diag_2))\n",
    "K_0 = np.dot(np.dot(D_0, K_0), D_0[:K_tr_0.shape[0]][:,:K_tr_0.shape[0]]) + 1\n",
    "K_1 = np.dot(np.dot(D_1, K_1), D_1[:K_tr_0.shape[0]][:,:K_tr_0.shape[0]]) + 1\n",
    "K_2 = np.dot(np.dot(D_2, K_2), D_2[:K_tr_0.shape[0]][:,:K_tr_0.shape[0]]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('features/K_0_mis_sub_9-2.npy', K_0)\n",
    "np.save('features/K_1_mis_sub_9-2.npy', K_1)\n",
    "np.save('features/K_2_mis_sub_9-2.npy', K_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Combine kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_0_9 = np.load('features/K_0_mis_sub_9-2.npy')\n",
    "K_1_9 = np.load('features/K_1_mis_sub_9-2.npy')\n",
    "K_2_9 = np.load('features/K_2_mis_sub_9-2.npy')\n",
    "\n",
    "K_0_8 = np.load('features/K_0_mismatch_8-2.npy')[:,:2000]\n",
    "K_1_8 = np.load('features/K_1_mismatch_8-2.npy')[:,:2000]\n",
    "K_2_8 = np.load('features/K_2_mismatch_8-2.npy')[:,:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('features/K_0_mismatch_8-2.npy', K_0_8-1)\n",
    "np.save('features/K_1_mismatch_8-2.npy', K_1_8-1)\n",
    "np.save('features/K_2_mismatch_8-2.npy', K_2_8-1)\n",
    "\n",
    "np.save('features/K_0_mismatch_9-2.npy', K_0_9-1)\n",
    "np.save('features/K_1_mismatch_9-2.npy', K_1_9-1)\n",
    "np.save('features/K_2_mismatch_9-2.npy', K_2_9-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_versions = ['5-1', '5-2', '6-1', '6-2', '7-1', '7-2', '8-1', '8-2', '9-1', '9-2']\n",
    "K_0_dict, K_1_dict, K_2_dict = {}, {}, {}\n",
    "\n",
    "for version in kernel_versions:\n",
    "    K_0_dict[version] = np.load(f'features/K_0_mismatch_{version}.npy')\n",
    "    K_1_dict[version] = np.load(f'features/K_1_mismatch_{version}.npy')\n",
    "    K_2_dict[version] = np.load(f'features/K_2_mismatch_{version}.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666736 0.9812609 0.71469575 0.9334555 0.58508676 0.83338505 0.50571245 0.68502593 0.454753 0.5665562\n",
      "0.13756227 0.41658652 0.044690106 0.24268545 0.00861483 0.13032505 0.006316263 0.045187116 0.0 0.034760356\n"
     ]
    }
   ],
   "source": [
    "print(K_0_dict['5-1'][0,1:].max(), K_0_dict['5-2'][0,1:].max(), K_0_dict['6-1'][1:,0].max(), K_0_dict['6-2'][1:,0].max(), K_0_dict['7-1'][1:,0].max(), K_0_dict['7-2'][1:,0].max(), K_0_dict['8-1'][1:,0].max(), K_0_dict['8-2'][1:,0].max(), K_0_dict['9-1'][1:,0].max(), K_0_dict['9-2'][1:,0].max())\n",
    "print(K_1_dict['5-1'][0,1:].min(), K_1_dict['5-2'][0,1:].min(), K_1_dict['6-1'][1:,0].min(), K_1_dict['6-2'][1:,0].min(), K_1_dict['7-1'][1:,0].min(), K_1_dict['7-2'][1:,0].min(), K_0_dict['8-1'][1:,0].min(), K_1_dict['8-2'][1:,0].min(), K_1_dict['9-1'][1:,0].min(), K_0_dict['9-2'][1:,0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean of kernels\n",
    "kernel_versions = ['8-2', '9-2']\n",
    "K_0_mean = np.mean([K_0_dict[version][:,:2000] for version in kernel_versions], axis=0) + 1\n",
    "K_1_mean = np.mean([K_1_dict[version][:,:2000] for version in kernel_versions], axis=0) + 1\n",
    "K_2_mean = np.mean([K_2_dict[version][:,:2000] for version in kernel_versions], axis=0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Product of kernels\n",
    "kernel_versions_1 = ['8-1', '9-1']\n",
    "K_0_prod_1 = np.prod([K_0_dict[version][:,:2000] for version in kernel_versions_1], axis=0)\n",
    "K_1_prod_1 = np.prod([K_1_dict[version][:,:2000] for version in kernel_versions_1], axis=0)\n",
    "K_2_prod_1 = np.prod([K_2_dict[version][:,:2000] for version in kernel_versions_1], axis=0)\n",
    "kernel_versions_2 = ['8-2', '9-2']\n",
    "K_0_prod_2 = np.prod([K_0_dict[version][:,:2000] for version in kernel_versions_2], axis=0)\n",
    "K_1_prod_2 = np.prod([K_1_dict[version][:,:2000] for version in kernel_versions_2], axis=0)\n",
    "K_2_prod_2 = np.prod([K_2_dict[version][:,:2000] for version in kernel_versions_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal kernel (gives 100% accuracy on the training set)\n",
    "K_0_opt = Ytr0[:,None]*Ytr0[None,:]\n",
    "K_1_opt = Ytr1[:,None]*Ytr1[None,:]\n",
    "K_2_opt = Ytr2[:,None]*Ytr2[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment(K_a, K_a_opt):\n",
    "    return np.sum(K_a[:2000]*K_a_opt)/np.sqrt(np.sum(K_a[:2000]**2)*np.sum(K_a_opt**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dataset 0\n",
    "w_0_prod_1 = alignment(K_0_prod_1, K_0_opt)\n",
    "w_0_prod_2 = alignment(K_0_prod_2, K_0_opt)\n",
    "w_0 = w_0_prod_1 + w_0_prod_2\n",
    "K_0 = K_0_prod_1**(w_0_prod_1/w_0)*K_0_prod_2**(w_0_prod_2/w_0) + 1\n",
    "\n",
    "# For dataset 1\n",
    "w_1_prod_1 = alignment(K_1_prod_1, K_1_opt)\n",
    "w_1_prod_2 = alignment(K_1_prod_2, K_1_opt)\n",
    "w_1 = w_1_prod_1 + w_1_prod_2\n",
    "K_1 = K_1_prod_1**(w_1_prod_1/w_1)*K_1_prod_2**(w_1_prod_2/w_1) + 1\n",
    "\n",
    "# For dataset 2\n",
    "w_2_prod_1 = alignment(K_2_prod_1, K_2_opt)\n",
    "w_2_prod_2 = alignment(K_2_prod_2, K_2_opt)\n",
    "w_2 = w_2_prod_1 + w_2_prod_2\n",
    "K_2 = K_2_prod_1**(w_2_prod_1/w_2)*K_2_prod_2**(w_2_prod_2/w_2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_0 = (K_0_prod_1*K_0_prod_2)**(1/2) + 1\n",
    "K_1 = (K_1_prod_1*K_1_prod_2)**(1/2) + 1\n",
    "K_2 = (K_2_prod_1*K_2_prod_2)**(1/2) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Local Alignment Kernel  : <span style=\"color:green\">TODO / Time Complexity too high + value too high</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Local Alignment Kernel defined as:\n",
    "$$K_{LA}^{(\\beta)}(x,y) = \\sum_{\\pi\\in\\Pi(x,y)} s_{S,g}(\\pi)$$\n",
    "\n",
    "is symmetric positive definite.\n",
    "\n",
    "We assume an affine gap penalty:\n",
    "$$\\left\\{\\begin{aligned}\n",
    "&g(0) = 0 \\\\\n",
    "&g(n) = d + e(n-1) \\quad \\text{for } n>0\n",
    "\\end{aligned}\\right.$$\n",
    "\n",
    "where $l(\\pi)$ is the length of the alignment $\\pi$.\n",
    "\n",
    "We use the formula for the Local Alignment Kernel:\n",
    "$$K_{LA}^{(\\beta)}(x,y) = 1 + X_2(|x|,|y|)+ Y_2(|x|,|y|) + M(|x|,|y|)$$ \n",
    "where $X_2$, $Y_2$ and $M$ are defined recursively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Run Kernel Method on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the eigenvalues of K_0\n",
    "eigenvalues, _ = np.linalg.eigh(K_gaussian)\n",
    "\n",
    "# Find the smallest eigenvalue\n",
    "min_eigenvalue = np.min(eigenvalues)\n",
    "\n",
    "# If the smallest eigenvalue is negative, adjust the diagonal\n",
    "if min_eigenvalue < 0:\n",
    "    K_gaussian += np.eye(K_gaussian.shape[0]) * (-min_eigenvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "solver=SVM_solver #quad_solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Dataset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9994444444444445, 0.65)"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method\n",
    "lambd = 1e-4\n",
    "method_0 = KernelMethod(K_0[:, :2000], Ytr0, solver=solver)\n",
    "method_0.lambd = lambd\n",
    "method_0.train_test_split(test_size=0.1)\n",
    "method_0.fit()\n",
    "method_0.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "method_0.grid_search(np.logspace(-5, -3, 10), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for pow\n",
    "pow_values = np.linspace(2, 3, 5)\n",
    "\n",
    "# Perform grid search\n",
    "best_pow = None\n",
    "best_accuracy = -np.inf\n",
    "\n",
    "for pow in pow_values:\n",
    "    method_2 = KernelMethod((K_0_dict['9-2']**pow)[:2000][:, :2000], Ytr0, lambd=lambd, solver=SVM_solver)\n",
    "    method_2.train_test_split(test_size=0.1)\n",
    "    accuracy = method_2.validate(test_size=0.1, n_splits=10)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_pow = pow\n",
    "\n",
    "print(f\"Best pow: {best_pow}\")\n",
    "print(f\"Best average accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.609\n",
      "Min Accuracy: 0.585 Max Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_0.validate(test_size=0.1, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.63825\n",
      "Min Accuracy: 0.57 Max Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_0.validate(test_size=0.1, n_splits=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.845)"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambd_1 = 1e-4\n",
    "\n",
    "method_1 = KernelMethod((K_1)[:2000][:, :2000], Ytr1, lambd=lambd_1, solver=SVM_solver)\n",
    "method_1.train_test_split(test_size=0.1)\n",
    "method_1.fit()\n",
    "method_1.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 1e-05, Accuracy: 0.79\n",
      "Lambda: 1.6681005372000593e-05, Accuracy: 0.80\n",
      "Lambda: 2.782559402207126e-05, Accuracy: 0.79\n",
      "Lambda: 4.641588833612782e-05, Accuracy: 0.80\n",
      "Lambda: 7.742636826811278e-05, Accuracy: 0.79\n",
      "Lambda: 0.0001291549665014884, Accuracy: 0.79\n",
      "Lambda: 0.00021544346900318823, Accuracy: 0.79\n",
      "Lambda: 0.00035938136638046257, Accuracy: 0.79\n",
      "Lambda: 0.0005994842503189409, Accuracy: 0.74\n",
      "Lambda: 0.001, Accuracy: 0.71\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.641588833612782e-05, 80.30000000000001)"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search for lambda\n",
    "method_1.grid_search(np.logspace(-5, -3, 10), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for pow\n",
    "pow_values = np.linspace(0.5, 2, 5)\n",
    "\n",
    "# Perform grid search\n",
    "best_pow = None\n",
    "best_accuracy = -np.inf\n",
    "\n",
    "for pow in pow_values:\n",
    "    method_2 = KernelMethod(((K_1-1)**pow+1)[:2000][:, :2000], Ytr1, lambd=lambd_1, solver=SVM_solver)\n",
    "    method_2.train_test_split(test_size=0.1)\n",
    "    accuracy = method_2.validate(test_size=0.1, n_splits=10)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_pow = pow\n",
    "\n",
    "print(f\"Best pow: {best_pow}\")\n",
    "print(f\"Best average accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.7905\n",
      "Min Accuracy: 0.755 Max Accuracy: 0.815\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_1.validate(test_size=0.1, n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = K_2_dict['9-1'][:,:2000]*K_2_dict['9-2'][:,:2000]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.69)"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambd_2 = 1e-4\n",
    "\n",
    "method_2 = KernelMethod(test[:2000][:, :2000], Ytr2, lambd=lambd_2, solver=SVM_solver)\n",
    "method_2.train_test_split(test_size=0.1)\n",
    "method_2.fit()\n",
    "method_2.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 1e-05, Accuracy: 0.68\n",
      "Lambda: 1.6681005372000593e-05, Accuracy: 0.67\n",
      "Lambda: 2.782559402207126e-05, Accuracy: 0.68\n",
      "Lambda: 4.641588833612782e-05, Accuracy: 0.71\n",
      "Lambda: 7.742636826811278e-05, Accuracy: 0.69\n",
      "Lambda: 0.0001291549665014884, Accuracy: 0.68\n",
      "Lambda: 0.00021544346900318823, Accuracy: 0.67\n",
      "Lambda: 0.00035938136638046257, Accuracy: 0.67\n",
      "Lambda: 0.0005994842503189409, Accuracy: 0.58\n",
      "Lambda: 0.001, Accuracy: 0.58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.641588833612782e-05, 70.6)"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search\n",
    "method_2.grid_search(np.logspace(-5, -3, 10), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for pow\n",
    "pow_values = np.linspace(0.5, 3, 10)\n",
    "\n",
    "# Perform grid search\n",
    "best_pow = None\n",
    "best_accuracy = -np.inf\n",
    "\n",
    "for pow in pow_values:\n",
    "    method_2 = KernelMethod((K_2**pow)[:2000][:, :2000], Ytr2, lambd=lambd_2, solver=SVM_solver)\n",
    "    method_2.train_test_split(test_size=0.1)\n",
    "    accuracy = method_2.validate(test_size=0.1, n_splits=20)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_pow = pow\n",
    "\n",
    "print(f\"Best pow: {best_pow}\")\n",
    "print(f\"Best average accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.6880000000000001\n",
      "Min Accuracy: 0.645 Max Accuracy: 0.735\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_2.validate(test_size=0.1, n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Apply Kernel Predictor on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_labels(K, method):\n",
    "    K_te = K\n",
    "    alpha = method.alpha\n",
    "    # Predictions\n",
    "    Yte0 = np.sign(K_te @ alpha)\n",
    "    return Yte0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte_file_name = 'Yte_mismatch_9x8-1-2.csv'\n",
    "\n",
    "Yte0 = predict_test_labels(K_0[2000:][:, method_0.train_indices], method_0)\n",
    "Yte1 = predict_test_labels(K_1[2000:][:,method_1.train_indices], method_1)\n",
    "Yte2 = predict_test_labels(test[2000:][:,method_2.train_indices], method_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte = pd.read_csv('Yte_mismatch_9x8.csv', index_col=0)\n",
    "Yte0 = Yte['Bound'].values[:1000]*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte_file_name = 'Yte_mismatch_9x8-1-2.csv'\n",
    "\n",
    "# Concatenate and add Id column\n",
    "Yte = np.concatenate([Yte0, Yte1, Yte2])\n",
    "Yte = pd.DataFrame(data=(Yte + 1) // 2, columns=['Bound'], dtype='int64')\n",
    "Yte.insert(0, 'Id', Yte.index)\n",
    "\n",
    "# Save the predictions\n",
    "Yte.to_csv(Yte_file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
