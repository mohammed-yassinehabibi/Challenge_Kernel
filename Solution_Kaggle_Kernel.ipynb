{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import py_stringmatching as sm\n",
    "import osqp\n",
    "from collections import Counter\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "from Local_packages.kernels import compute_kernel_matrix, gaussian_kernel, normalize\n",
    "from Local_packages.run import KernelMethod\n",
    "from Local_packages.optimizer import KLR_solver, SVM_solver\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "Xtr0 = pd.read_csv('data/Xtr0.csv', index_col=0)\n",
    "Xtr1 = pd.read_csv('data/Xtr1.csv', index_col=0)\n",
    "Xtr2 = pd.read_csv('data/Xtr2.csv',  index_col=0)\n",
    "Xte0 = pd.read_csv('data/Xte0.csv', index_col=0)\n",
    "Xte1 = pd.read_csv('data/Xte1.csv', index_col=0)\n",
    "Xte2 = pd.read_csv('data/Xte2.csv', index_col=0)\n",
    "\n",
    "Xtr0_Xte0 = pd.concat([Xtr0, Xte0], ignore_index=True)\n",
    "Xtr1_Xte1 = pd.concat([Xtr1, Xte1], ignore_index=True)\n",
    "Xtr2_Xte2 = pd.concat([Xtr2, Xte2], ignore_index=True)\n",
    "\n",
    "# Load the labels\n",
    "Ytr0 = pd.read_csv('data/Ytr0.csv', index_col=0)\n",
    "Ytr1 = pd.read_csv('data/Ytr1.csv', index_col=0)\n",
    "Ytr2 = pd.read_csv('data/Ytr2.csv', index_col=0)\n",
    "# Convert the labels to -1, 1\n",
    "Ytr0 = 2*Ytr0['Bound'].values - 1\n",
    "Ytr1 = 2*Ytr1['Bound'].values - 1\n",
    "Ytr2 = 2*Ytr2['Bound'].values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrix representation of the sequences\n",
    "Xtr0_mat100 = pd.read_csv('data/Xtr0_mat100.csv', header=None, sep=' ').values\n",
    "Xtr1_mat100 = pd.read_csv('data/Xtr1_mat100.csv', header=None, sep=' ').values\n",
    "Xtr2_mat100 = pd.read_csv('data/Xtr2_mat100.csv', header=None, sep=' ').values\n",
    "Xte0_mat100 = pd.read_csv('data/Xte0_mat100.csv', header=None, sep=' ').values\n",
    "Xte1_mat100 = pd.read_csv('data/Xte1_mat100.csv', header=None, sep=' ').values\n",
    "Xte2_mat100 = pd.read_csv('data/Xte2_mat100.csv', header=None, sep=' ').values\n",
    "\n",
    "Xtr0_Xte0_mat100 = np.concatenate([Xtr0_mat100, Xte0_mat100], axis=0)\n",
    "Xtr1_Xte1_mat100 = np.concatenate([Xtr1_mat100, Xte1_mat100], axis=0)\n",
    "Xtr2_Xte2_mat100 = np.concatenate([Xtr2_mat100, Xte2_mat100], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Compute Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gkm_kernel(seq1, seq2, k=3, gap=1):\n",
    "    \"\"\"Compute the gapped k-mer kernel between two sequences.\"\"\"\n",
    "    def extract_gapped_kmers(seq, k, gap):\n",
    "        kmers = set()\n",
    "        for i in range(len(seq) - (k + gap - 1)):\n",
    "            kmers.add(seq[i] + seq[i + gap + 1 : i + gap + k])  # gapped k-mer\n",
    "        return kmers\n",
    "    \n",
    "    kmers1 = extract_gapped_kmers(seq1, k, gap)\n",
    "    kmers2 = extract_gapped_kmers(seq2, k, gap)\n",
    "    \n",
    "    return len(kmers1.intersection(kmers2))  # Kernel similarity score\n",
    "\n",
    "def compute_row(i, X_left, X_right, k, gap):\n",
    "    \"\"\"Compute one row of the kernel matrix.\"\"\"\n",
    "    return [gkm_kernel(X_left[i], X_right[j], k, gap) for j in range(len(X_right))]\n",
    "\n",
    "def compute_gkm_kernel_matrix(X_left, X_right, k=3, gap=1, n_jobs=-1):\n",
    "    \"\"\"Compute the gapped k-mer kernel matrix using parallelization.\"\"\"\n",
    "    n_samples_left = len(X_left)\n",
    "    \n",
    "    kernel_matrix = Parallel(n_jobs=n_jobs)(\n",
    "      delayed(compute_row)(i, X_left, X_right, k, gap) for i in tqdm(range(n_samples_left))\n",
    "    )\n",
    "    \n",
    "    return np.array(kernel_matrix)\n",
    "\n",
    "# Example usage\n",
    "X_left = Xtr0_Xte0['seq'].to_list()\n",
    "X_right = Xtr0_Xte0['seq'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:42<00:00, 71.11it/s]\n",
      "100%|██████████| 3000/3000 [00:45<00:00, 65.77it/s]\n",
      "100%|██████████| 3000/3000 [00:48<00:00, 62.21it/s]\n"
     ]
    }
   ],
   "source": [
    "kernel_matrix_0 = compute_gkm_kernel_matrix(Xtr0_Xte0['seq'].to_list(), Xtr0_Xte0['seq'].to_list(), k=8, gap=5)\n",
    "K_0 = normalize(kernel_matrix_0)\n",
    "kernel_matrix_1 = compute_gkm_kernel_matrix(Xtr1_Xte1['seq'].to_list(), Xtr1_Xte1['seq'].to_list(), k=8, gap=5)\n",
    "K_1 = normalize(kernel_matrix_1)\n",
    "kernel_matrix_2 = compute_gkm_kernel_matrix(Xtr2_Xte2['seq'].to_list(), Xtr2_Xte2['seq'].to_list(), k=8, gap=5)\n",
    "K_2 = normalize(kernel_matrix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'mis_sub'\n",
    "\n",
    "#Gaussian Kernel - On the matrix representation of the sequences\n",
    "if kernel=='exp':\n",
    "    args = {'sigma': 0.13}\n",
    "#Smith-Waterman Local Alignment Score\n",
    "elif kernel=='sw':\n",
    "    args = {'sw': sm.SmithWaterman()}\n",
    "#Spectrum Kernel\n",
    "elif kernel=='spect':\n",
    "    args = {'k': 5}\n",
    "#Mismatch Kernel\n",
    "elif kernel=='mismatch':\n",
    "    args = {'k': 10, 'm': 2}\n",
    "elif kernel=='mis_sub':\n",
    "    args = {'k': 10, 'm': 2}\n",
    "#LA Kernel\n",
    "elif kernel=='LA':\n",
    "    args = {'beta': 0.5, 'd': 11, 'e': 1}\n",
    "elif kernel=='LA_gpu':\n",
    "    args = {'beta': 0.5, 'd': 1, 'e': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_0 = compute_kernel_matrix(Xtr0, Xtr0, kernel, **args)\n",
    "K_1 = compute_kernel_matrix(Xtr1, Xte1, kernel, **args)\n",
    "K_2 = compute_kernel_matrix(Xtr2, Xte2, kernel, **args)\n",
    "\n",
    "#K_0 = compute_kernel_matrix(Xtr0_Xte0, Xtr0_Xte0, kernel, **args)\n",
    "#K_1 = compute_kernel_matrix(Xtr1_Xte1, Xtr1_Xte1, kernel, **args)\n",
    "#K_2 = compute_kernel_matrix(Xtr2_Xte2, Xtr2_Xte2, kernel, **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('features/K_0_tr_mismatch_10-2.npy', K_0)\n",
    "np.save('features/K_1_te_mismatch_10-2.npy', K_1.T)\n",
    "np.save('features/K_2_te_mismatch_10-2.npy', K_2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute only the diagonal of the kernel matrix for the test set\n",
    "def compute_kernel_for_row(i, Xte, kernel, args):\n",
    "    return compute_kernel_matrix(Xte.iloc[[i]], Xte.iloc[[i]], kernel, **args)\n",
    "\n",
    "#K_te_0 = np.concatenate(Parallel(n_jobs=-1)(delayed(compute_kernel_for_row)(i, Xte0, kernel, args) for i in tqdm(range(len(Xte0)))), axis=0)\n",
    "K_te_1 = np.concatenate(Parallel(n_jobs=-1)(delayed(compute_kernel_for_row)(i, Xte1, kernel, args) for i in tqdm(range(len(Xte1)))), axis=0)\n",
    "K_te_2 = np.concatenate(Parallel(n_jobs=-1)(delayed(compute_kernel_for_row)(i, Xte2, kernel, args) for i in tqdm(range(len(Xte2)))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('features/K_0_tr_mismatch_10-2.npy', K_0)\n",
    "np.save('features/K_1_te_diag_mismatch_10-2.npy', K_te_1)\n",
    "np.save('features/K_2_te_diag_mismatch_10-2.npy', K_te_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Merge sub-kernels into one kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the kernel matrices on Xtr x Xtr\n",
    "K_tr_0 = np.load('features/K_0_tr_mismatch_10-2.npy')\n",
    "K_tr_1 = np.load('features/K_1_tr_mismatch_10-2.npy')\n",
    "K_tr_2 = np.load('features/K_2_tr_mismatch_10-2.npy')\n",
    "# Load the kernel vector on {Xte_i, Xte_i}_i\n",
    "K_te_0 = np.load('features/K_0_te_diag_mismatch_10-2.npy')\n",
    "K_te_1 = np.load('features/K_1_te_diag_mismatch_10-2.npy')\n",
    "K_te_2 = np.load('features/K_2_te_diag_mismatch_10-2.npy')\n",
    "# Concatenate the kernel vector on {Xtr_i, Xte_i}_i and {Xte_i, Xte_i}_i to get the diagonal of the whole kernel matrix K \n",
    "K_diag_0 = np.concatenate([np.diag(K_tr_0),K_te_0.flatten()], axis=0)\n",
    "K_diag_1 = np.concatenate([np.diag(K_tr_1),K_te_1.flatten()], axis=0)\n",
    "K_diag_2 = np.concatenate([np.diag(K_tr_2),K_te_2.flatten()], axis=0)\n",
    "# Load the kernel matrices on Xte x Xtr\n",
    "K_tr_te_0 = np.load('features/K_0_te_mismatch_10-2.npy')\n",
    "K_tr_te_1 = np.load('features/K_1_te_mismatch_10-2.npy')\n",
    "K_tr_te_2 = np.load('features/K_2_te_mismatch_10-2.npy')\n",
    "# Concatenate the kernel matrices on Xtr x Xtr and Xte x Xtr to get the whole kernel matrix K on (Xtr U Xte) x Xtr\n",
    "K_0 = np.concatenate([K_tr_0, K_tr_te_0], axis=0)\n",
    "K_1 = np.concatenate([K_tr_1, K_tr_te_1], axis=0)\n",
    "K_2 = np.concatenate([K_tr_2, K_tr_te_2], axis=0)\n",
    "# Normalize the kernel matrix K\n",
    "D_0 = np.diag(1/np.sqrt(K_diag_0))\n",
    "D_1 = np.diag(1/np.sqrt(K_diag_1))\n",
    "D_2 = np.diag(1/np.sqrt(K_diag_2))\n",
    "K_0 = np.dot(np.dot(D_0, K_0), D_0[:K_tr_0.shape[0]][:,:K_tr_0.shape[0]]) \n",
    "K_1 = np.dot(np.dot(D_1, K_1), D_1[:K_tr_0.shape[0]][:,:K_tr_0.shape[0]]) \n",
    "K_2 = np.dot(np.dot(D_2, K_2), D_2[:K_tr_0.shape[0]][:,:K_tr_0.shape[0]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('features/K_0_mismatch_10-2.npy', K_0)\n",
    "np.save('features/K_1_mismatch_10-2.npy', K_1)\n",
    "np.save('features/K_2_mismatch_10-2.npy', K_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Load kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_versions = ['5-1', '5-2', '6-1', '6-2', '7-1', '7-2', '8-1', '8-2', '9-1', '9-2', '10-2']\n",
    "K_0_dict, K_1_dict, K_2_dict = {}, {}, {}\n",
    "\n",
    "for version in kernel_versions:\n",
    "    K_0_dict[version] = np.load(f'features/K_0_mismatch_{version}.npy')\n",
    "    K_1_dict[version] = np.load(f'features/K_1_mismatch_{version}.npy')\n",
    "    K_2_dict[version] = np.load(f'features/K_2_mismatch_{version}.npy')\n",
    "\n",
    "# Load the additional kernel matrix\n",
    "#K_0_dict['exp-0_1'] = np.load('features/K_0_exp-0_1.npy')\n",
    "#K_1_dict['exp-0_1'] = np.load('features/K_1_exp-0_1.npy')\n",
    "#K_2_dict['exp-0_1'] = np.load('features/K_2_exp-0_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50571245 0.68502593 0.454753 0.5665562 0.4964234\n",
      "0.006316263 0.045187116 0.0 0.034760356 0.0020040865\n"
     ]
    }
   ],
   "source": [
    "print(K_0_dict['8-1'][1:,0].max(), K_0_dict['8-2'][1:,0].max(), K_0_dict['9-1'][1:,0].max(), K_0_dict['9-2'][1:,0].max(), K_0_dict['10-2'][1:,0].max())\n",
    "print(K_0_dict['8-1'][1:,0].min(), K_1_dict['8-2'][1:,0].min(), K_1_dict['9-1'][1:,0].min(), K_0_dict['9-2'][1:,0].min(), K_1_dict['10-2'][1:,0].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Combine kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_versions = ['9-2', '10-2']\n",
    "K_0_prod_2 = np.prod([K_0_dict[version][:,:2000] for version in kernel_versions], axis=0)\n",
    "K_1_prod_2 = np.prod([K_1_dict[version][:,:2000] for version in kernel_versions], axis=0)\n",
    "K_2_prod_2 = np.prod([K_2_dict[version][:,:2000] for version in kernel_versions], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exponential kernel from concatenation of kernels\n",
    "#Concatenate Kernels\n",
    "kernel_versions = ['5-2', '6-2', '9-2', '8-2']\n",
    "K_0_concat = np.stack([K_0_dict[version][:, :2000] for version in kernel_versions], axis=-1)\n",
    "K_1_concat = np.stack([K_1_dict[version][:, :2000] for version in kernel_versions], axis=-1)\n",
    "K_2_concat = np.stack([K_2_dict[version][:, :2000] for version in kernel_versions], axis=-1)\n",
    "#Take norm Kernel\n",
    "K_0_exp = np.exp(np.linalg.norm(K_0_concat, axis=-1))\n",
    "K_1_exp = np.exp(np.linalg.norm(K_1_concat, axis=-1))\n",
    "K_2_exp = np.exp(np.linalg.norm(K_2_concat, axis=-1))\n",
    "K_0_norm = np.linalg.norm(K_0_concat, axis=-1)\n",
    "K_1_norm = np.linalg.norm(K_1_concat, axis=-1)\n",
    "K_2_norm = np.linalg.norm(K_2_concat, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal kernel (gives 100% accuracy on the training set)\n",
    "K_0_opt = ((Ytr0+1)/2)[:,None]*((Ytr0+1)/2)[None,:]\n",
    "K_1_opt = ((Ytr1+1)/2)[:,None]*((Ytr1+1)/2)[None,:]\n",
    "K_2_opt = ((Ytr2+1)/2)[:,None]*((Ytr2+1)/2)[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment(K_a, K_a_opt):\n",
    "    return np.sum(K_a[:2000]*K_a_opt)/np.sqrt(np.sum(K_a[:2000]**2)*np.sum(K_a_opt**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_versions = ['5-1', '5-2', '6-1', '6-2', '7-1', '7-2', '8-1', '8-2', '9-1', '9-2']\n",
    "for kernel_version in kernel_versions:\n",
    "    print(alignment(K_2_dict[kernel_version][:,:2000],K_2_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dataset 0\n",
    "w_0_prod_1 = alignment(K_0_prod_1, K_0_opt)\n",
    "w_0_prod_2 = alignment(K_0_prod_2, K_0_opt)\n",
    "w_0 = w_0_prod_1 + w_0_prod_2\n",
    "K_0 = K_0_prod_1**(w_0_prod_1/w_0)*K_0_prod_2**(w_0_prod_2/w_0) + 1\n",
    "\n",
    "# For dataset 1\n",
    "w_1_prod_1 = alignment(K_1_prod_1, K_1_opt)\n",
    "w_1_prod_2 = alignment(K_1_prod_2, K_1_opt)\n",
    "w_1 = w_1_prod_1 + w_1_prod_2\n",
    "K_1 = K_1_prod_1**(w_1_prod_1/w_1)*K_1_prod_2**(w_1_prod_2/w_1) + 1\n",
    "\n",
    "# For dataset 2\n",
    "w_2_prod_1 = alignment(K_2_prod_1, K_2_opt)\n",
    "w_2_prod_2 = alignment(K_2_prod_2, K_2_opt)\n",
    "w_2 = w_2_prod_1 + w_2_prod_2\n",
    "K_2 = K_2_prod_1**(w_2_prod_1/w_2)*K_2_prod_2**(w_2_prod_2/w_2) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Local Alignment Kernel  : <span style=\"color:green\">TODO / Time Complexity too high + value too high</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Local Alignment Kernel defined as:\n",
    "$$K_{LA}^{(\\beta)}(x,y) = \\sum_{\\pi\\in\\Pi(x,y)} s_{S,g}(\\pi)$$\n",
    "\n",
    "is symmetric positive definite.\n",
    "\n",
    "We assume an affine gap penalty:\n",
    "$$\\left\\{\\begin{aligned}\n",
    "&g(0) = 0 \\\\\n",
    "&g(n) = d + e(n-1) \\quad \\text{for } n>0\n",
    "\\end{aligned}\\right.$$\n",
    "\n",
    "where $l(\\pi)$ is the length of the alignment $\\pi$.\n",
    "\n",
    "We use the formula for the Local Alignment Kernel:\n",
    "$$K_{LA}^{(\\beta)}(x,y) = 1 + X_2(|x|,|y|)+ Y_2(|x|,|y|) + M(|x|,|y|)$$ \n",
    "where $X_2$, $Y_2$ and $M$ are defined recursively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Run Kernel Method on Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Dataset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_0_concat = np.stack([K_0_dict[version][:, :2000] for version in ['8-2', '9-2', '5-1']], axis=-1)\n",
    "K_0_norm = np.exp(np.linalg.norm(K_0_concat, axis=-1)-2)\n",
    "#K_0_norm = np.exp(np.linalg.norm(K_0_concat, axis=-1))\n",
    "K_0 = K_0_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7649466 , 0.28438875, 0.29345217, ..., 0.23277202, 0.2676232 ,\n",
       "       0.24363628], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9994444444444445, 0.625)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method\n",
    "lambd = 5e-5\n",
    "method_0 = KernelMethod(K_0[:2000, :2000], Ytr0, solver=SVM_solver)\n",
    "method_0.lambd = lambd\n",
    "method_0.train_test_split(test_size=0.1, random_state=1000)\n",
    "method_0.fit()\n",
    "method_0.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:38<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.6357250000000001\n",
      "Min Accuracy: 0.555 Max Accuracy: 0.735\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_0.validate(test_size=0.1, n_splits=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:39<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.633675\n",
      "Min Accuracy: 0.54 Max Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_0.validate(test_size=0.1, n_splits=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 4976.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5820000000000001"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_0_dict['special'] = K_0-1\n",
    "K_0_s = np.stack([K_0_dict[version][:, :2000]+1 for version in ['special', '10-2', '9-1', '8-1']], axis=0)\n",
    "\n",
    "def train_model(seed):\n",
    "    methods = []\n",
    "    lambd = 5e-5\n",
    "\n",
    "    for K in K_0_s:\n",
    "        K_0 = K[:, :2000] + 1\n",
    "        method = KernelMethod(K_0[:2000, :2000], Ytr0, solver=SVM_solver)\n",
    "        method.lambd = lambd\n",
    "        method.train_test_split(test_size=0.1, random_state=seed)\n",
    "        method.fit()\n",
    "        method.evaluate()\n",
    "        methods.append(method)\n",
    "\n",
    "    return methods\n",
    "\n",
    "# List of seeds\n",
    "seeds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Run in parallel\n",
    "all_methods = Parallel(n_jobs=-1)(delayed(train_model)(seed) for seed in tqdm(seeds))\n",
    "\n",
    "def evaluate(models):\n",
    "    m_train = np.array([np.dot(model.kernel[model.train_indices][:, model.train_indices], model.alpha) for model in models])\n",
    "    m_train_sgn = np.sign(m_train)\n",
    "    m_train_agg = np.sign(np.mean(m_train_sgn, axis=0))\n",
    "    train_accuracy = np.mean(m_train_agg == models[0].Y[models[0].train_indices])\n",
    "\n",
    "    m_test = np.array([np.dot(model.kernel[model.test_indices][:, model.train_indices], model.alpha) for model in models])\n",
    "    m_test_sgn = np.sign(m_test)\n",
    "    m_test_agg = np.sign(np.mean(m_test_sgn, axis=0))\n",
    "    test_accuracy = np.mean(m_test_agg == models[0].Y[models[0].test_indices])\n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "# Evaluate for the first set of methods\n",
    "evaluations = [evaluate([method for method in methods]) for methods in all_methods]\n",
    "np.array(evaluations)[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "method_0.grid_search(np.logspace(-5, -3, 10), test_size=0.1, n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for pow\n",
    "pow_values = np.linspace(0.01, 0.1, 3)\n",
    "\n",
    "# Perform grid search\n",
    "best_pow = None\n",
    "best_accuracy = -np.inf\n",
    "\n",
    "for pow in pow_values:\n",
    "    method_0 = KernelMethod((K_0_exp**pow)[:2000][:, :2000], Ytr0, lambd=lambd, solver=SVM_solver)\n",
    "    method_0.train_test_split(test_size=0.1)\n",
    "    accuracy = method_0.validate(test_size=0.1, n_splits=10)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_pow = pow\n",
    "\n",
    "print(f\"Best pow: {best_pow}\")\n",
    "print(f\"Best average accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BEST AVERAGE ACCURACY : 64.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_0_concat = np.stack([K_0_dict[version][:, :2000] for version in ['8-2', '9-2', '5-1']], axis=-1)\n",
    "K_0_norm = np.linalg.norm(K_0_concat, axis=-1)\n",
    "K_0 = K_0_norm+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_1 = K_1_dict['9-2'][:,:2000]**2 # lambd_2 = 1e-4 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.00653302, 0.02531799, ..., 0.02429392, 0.04268699,\n",
       "        0.00788511],\n",
       "       [0.00653302, 1.        , 0.01486757, ..., 0.00698799, 0.00678186,\n",
       "        0.01230289],\n",
       "       [0.02531799, 0.01486757, 1.        , ..., 0.02443128, 0.01686409,\n",
       "        0.0100904 ],\n",
       "       ...,\n",
       "       [0.03528198, 0.01087151, 0.01675584, ..., 0.04444053, 0.02422663,\n",
       "        0.01020658],\n",
       "       [0.00957606, 0.01095784, 0.02077249, ..., 0.04816468, 0.01277906,\n",
       "        0.01438896],\n",
       "       [0.00749621, 0.01976574, 0.01067438, ..., 0.01590941, 0.01205017,\n",
       "        0.02235378]], dtype=float32)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.81)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambd_1 = 1e-4\n",
    "\n",
    "method_1 = KernelMethod((K_1+1)[:2000], Ytr1, lambd=lambd_1, solver=SVM_solver)\n",
    "method_1.train_test_split(test_size=0.1, random_state=10)\n",
    "method_1.fit()\n",
    "method_1.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search for lambda\n",
    "method_1.grid_search(np.logspace(-9, -7, 10), test_size=0.25, n_folds=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for pow\n",
    "pow_values = np.linspace(0.5, 2, 5)\n",
    "\n",
    "# Perform grid search\n",
    "best_pow = None\n",
    "best_accuracy = -np.inf\n",
    "\n",
    "for pow in pow_values:\n",
    "    method_2 = KernelMethod(((K_1_exp-1)**pow+1)[:2000][:, :2000], Ytr1, lambd=lambd_1, solver=SVM_solver)\n",
    "    method_2.train_test_split(test_size=0.1)\n",
    "    accuracy = method_2.validate(test_size=0.1, n_splits=10)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_pow = pow\n",
    "\n",
    "print(f\"Best pow: {best_pow}\")\n",
    "print(f\"Best average accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.7844\n",
      "Min Accuracy: 0.72 Max Accuracy: 0.855\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_1.validate(test_size=0.1, n_splits=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BEST AVERAGE ACCURACY : 79.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.7905\n",
      "Min Accuracy: 0.755 Max Accuracy: 0.815\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_1.validate(test_size=0.1, n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = K_2_dict['9-1'][:,:2000]*K_2_dict['9-2'][:,:2000]**2+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9994444444444445, 0.68)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambd_2 = 2e-4\n",
    "\n",
    "method_2 = KernelMethod((test)[:2000, :2000], Ytr2, lambd=lambd_2, solver=SVM_solver)\n",
    "method_2.train_test_split(test_size=0.1, random_state=10)\n",
    "method_2.fit()\n",
    "method_2.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "method_2.grid_search(np.logspace(-5, -3.5, 8), test_size=0.1, n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for pow\n",
    "pow_values = np.linspace(0.5, 3, 10)\n",
    "\n",
    "# Perform grid search\n",
    "best_pow = None\n",
    "best_accuracy = -np.inf\n",
    "\n",
    "for pow in pow_values:\n",
    "    method_2 = KernelMethod((K_2**pow)[:2000][:, :2000], Ytr2, lambd=lambd_2, solver=SVM_solver)\n",
    "    method_2.train_test_split(test_size=0.1)\n",
    "    accuracy = method_2.validate(test_size=0.1, n_splits=20)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_pow = pow\n",
    "\n",
    "print(f\"Best pow: {best_pow}\")\n",
    "print(f\"Best average accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.6972\n",
      "Min Accuracy: 0.61 Max Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_2.validate(test_size=0.05, n_splits=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BEST AVERAGE ACCURACY : 69.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.69575\n",
      "Min Accuracy: 0.64 Max Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "test = K_2_dict['9-1'][:,:2000]*K_2_dict['9-2'][:,:2000]**2+1 # lambd_2 = 1e-4 ?\n",
    "average_accuracy = method_2.validate(test_size=0.1, n_splits=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Apply Kernel Predictor on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_labels(K, method):\n",
    "    K_te = K\n",
    "    alpha = method.alpha\n",
    "    # Predictions\n",
    "    Yte0 = np.sign(K_te @ alpha)\n",
    "    return Yte0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte_file_name = 'Yte_mismatch_exp_8_9_5.csv'\n",
    "\n",
    "#Yte0 = predict_test_labels(K_0[2000:][:, method_0.train_indices], method_0)\n",
    "#Yte1 = predict_test_labels(K_1[2000:][:,method_1.train_indices], method_1)\n",
    "Yte2 = predict_test_labels(test[2000:][:,method_2.train_indices], method_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte = pd.read_csv('Yte_mismatch_9_10.csv', index_col=0)\n",
    "Yte0 = Yte['Bound'].values[:1000]*2-1\n",
    "Yte1 = Yte['Bound'].values[1000:2000]*2-1\n",
    "Yte2 = Yte['Bound'].values[2000:]*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte_file_name = 'Yte_mismatch_9_10_bias_1.csv'\n",
    "\n",
    "# Concatenate and add Id column\n",
    "Yte = np.concatenate([Yte0, Yte1, Yte2])\n",
    "Yte = pd.DataFrame(data=(Yte + 1) // 2, columns=['Bound'], dtype='int64')\n",
    "Yte.insert(0, 'Id', Yte.index)\n",
    "\n",
    "# Save the predictions\n",
    "Yte.to_csv(Yte_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
