{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import py_stringmatching as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution Proposed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "Xtr0 = pd.read_csv('data/Xtr0.csv', index_col=0)\n",
    "Xtr1 = pd.read_csv('data/Xtr1.csv', index_col=0)\n",
    "Xtr2 = pd.read_csv('data/Xtr2.csv',  index_col=0)\n",
    "# Load the matrix representation of the sequences\n",
    "Xtr0_mat100 = pd.read_csv('data/Xtr0_mat100.csv', header=None, sep=' ').values\n",
    "Xtr1_mat100 = pd.read_csv('data/Xtr1_mat100.csv', header=None, sep=' ').values\n",
    "Xtr2_mat100 = pd.read_csv('data/Xtr2_mat100.csv', header=None, sep=' ').values\n",
    "# Load the labels\n",
    "Ytr0 = pd.read_csv('data/Ytr0.csv', index_col=0)\n",
    "Ytr1 = pd.read_csv('data/Ytr1.csv', index_col=0)\n",
    "Ytr2 = pd.read_csv('data/Ytr2.csv', index_col=0)\n",
    "# Convert the labels to -1, 1\n",
    "Ytr0 = 2*Ytr0['Bound'].values - 1\n",
    "Ytr1 = 2*Ytr1['Bound'].values - 1\n",
    "Ytr2 = 2*Ytr2['Bound'].values - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Compute Kernel Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the kernel\n",
    "def lin_kernel(x, y):\n",
    "    return np.dot(x, y)\n",
    "\n",
    "def dist_kernel(x, y):\n",
    "    return np.linalg.norm(x-y)\n",
    "\n",
    "def exp_kernel(K_dist, sigma=1):\n",
    "    return np.exp(-K_dist**2/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_matrix(X_left, X_right):\n",
    "    # Initialize the distance matrix\n",
    "    K_dist = np.zeros((X_left.shape[0], X_right.shape[0]))\n",
    "\n",
    "    # Compute the distance matrix\n",
    "    for i in tqdm(range(X_left.shape[0]), desc=\"Computing distance matrix\"):\n",
    "        for j in range(X_right.shape[0]):\n",
    "            K_dist[i, j] = dist_kernel(X_left[i], X_right[j])\n",
    "    return K_dist\n",
    "\n",
    "# Example usage:\n",
    "K_dist0 = compute_distance_matrix(Xtr0_mat100, Xtr0_mat100)\n",
    "K_dist1 = compute_distance_matrix(Xtr1_mat100, Xtr1_mat100)\n",
    "K_dist2 = compute_distance_matrix(Xtr2_mat100, Xtr2_mat100)\n",
    "\n",
    "print(K_dist0.mean(), K_dist1.mean(), K_dist2.mean())\n",
    "print(K_dist0.std(), K_dist1.std(), K_dist2.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_exp_tr0 = exp_kernel(K_dist0, sigma=0.12)\n",
    "K_exp_tr1 = exp_kernel(K_dist1, sigma=0.13)\n",
    "K_exp_tr2 = exp_kernel(K_dist2, sigma=0.15)\n",
    "\n",
    "print(K_exp_tr0.mean(), K_exp_tr1.mean(), K_exp_tr2.mean())\n",
    "print(K_exp_tr0.std(), K_exp_tr1.std(), K_exp_tr2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Smith-Waterman Local Alignment Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smith-Waterman Local Alignment Score  $SW$ becomes a Kernel if we take  $\\widetilde{SW} = SW -\\lambda_{min}(SW)I$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sw_matrix(X_left, X_right, sw):\n",
    "    SW_matrix = np.zeros((X_left.shape[0], X_right.shape[0]))\n",
    "    #Symmetric case (X_left = X_right) : only compute the upper triangular part\n",
    "    if X_left is X_right:\n",
    "        for i in tqdm(range(X_left.shape[0]), desc=f\"Computing SW matrix for {X_left.shape[0]} sequences\"):\n",
    "            for j in range(i, X_right.shape[0]):\n",
    "                SW_matrix[i, j] = sw.get_raw_score(X_left['seq'].iloc[i], X_right['seq'].iloc[j])\n",
    "                SW_matrix[j, i] = SW_matrix[i, j]\n",
    "        return SW_matrix\n",
    "    #Non-symmetric case : compute the whole matrix\n",
    "    for i in tqdm(range(X_left.shape[0]), desc=f\"Computing SW matrix for {X_left.shape[0]} sequences\"):\n",
    "        for j in range(X_right.shape[0]):\n",
    "            SW_matrix[i, j] = sw.get_raw_score(X_left['seq'].iloc[i], X_right['seq'].iloc[j])\n",
    "    return SW_matrix\n",
    "\n",
    "# Compute SW matrices for the three datasets\n",
    "SW_tr0 = compute_sw_matrix(Xtr0, Xtr0, sm.SmithWaterman())\n",
    "SW_tr1 = compute_sw_matrix(Xtr1, Xtr1, sm.SmithWaterman())\n",
    "SW_tr2 = compute_sw_matrix(Xtr2, Xtr2, sm.SmithWaterman())\n",
    "\n",
    "print(SW_tr0.mean(), SW_tr1.mean(), SW_tr2.mean())\n",
    "print(SW_tr0.std(), SW_tr1.std(), SW_tr2.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('SW_tr0', SW_tr0)\n",
    "np.save('SW_tr1', SW_tr1)\n",
    "np.save('SW_tr2', SW_tr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Local Alignment Kernel  : <span style=\"color:green\">TODO / Time Complexity too high + value too high</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Local Alignment Kernel defined as:\n",
    "$$K_{LA}^{(\\beta)}(x,y) = \\sum_{\\pi\\in\\Pi(x,y)} s_{S,g}(\\pi)$$\n",
    "\n",
    "is symmetric positive definite.\n",
    "\n",
    "We assume an affine gap penalty:\n",
    "$$\\left\\{\\begin{aligned}\n",
    "&g(0) = 0 \\\\\n",
    "&g(n) = d + e(n-1) \\quad \\text{for } n>0\n",
    "\\end{aligned}\\right.$$\n",
    "\n",
    "where $l(\\pi)$ is the length of the alignment $\\pi$.\n",
    "\n",
    "We use the formula for the Local Alignment Kernel:\n",
    "$$K_{LA}^{(\\beta)}(x,y) = 1 + X_2(|x|,|y|)+ Y_2(|x|,|y|) + M(|x|,|y|)$$ \n",
    "where $X_2$, $Y_2$ and $M$ are defined recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the similarity function S (example: identity function)\n",
    "def S(a, b):\n",
    "    return 1 if a == b else 0\n",
    "\n",
    "def LA_Kernel(x, y, beta, d, e):\n",
    "    # Lengths of the sequences\n",
    "    len_x = len(x)\n",
    "    len_y = len(y)\n",
    "    # Initialize matrices\n",
    "    M = np.zeros((len_x + 1, len_y + 1))\n",
    "    X = np.zeros((len_x + 1, len_y + 1))\n",
    "    Y = np.zeros((len_x + 1, len_y + 1))\n",
    "    X2 = np.zeros((len_x + 1, len_y + 1))\n",
    "    Y2 = np.zeros((len_x + 1, len_y + 1))\n",
    "    # Fill the matrices using the recursive equations\n",
    "    for i in range(1, len_x + 1):\n",
    "        for j in range(1, len_y + 1):\n",
    "            # Compute M(i,j)\n",
    "            M[i][j] = np.exp(beta * S(x[i-1], y[j-1])) * (1 + X[i-1][j-1] + Y[i-1][j-1] + M[i-1][j-1])\n",
    "            # Compute X(i,j)\n",
    "            X[i][j] = np.exp(beta * d) * M[i-1][j] + np.exp(beta * e) * X[i-1][j]            \n",
    "            # Compute Y(i,j)\n",
    "            Y[i][j] = np.exp(beta * d) * (M[i][j-1] + X[i][j-1]) + np.exp(beta * e) * Y[i][j-1]\n",
    "            # Compute X2(i,j)\n",
    "            X2[i][j] = M[i-1][j] + X2[i-1][j]            \n",
    "            # Compute Y2(i,j)\n",
    "            Y2[i][j] = M[i][j-1] + X2[i][j-1] + Y2[i][j-1]\n",
    "    # Compute the LA kernel\n",
    "    K_LA = 1 + X2[len_x][len_y] + Y2[len_x][len_y] + M[len_x][len_y]\n",
    "    return K_LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = .05\n",
    "d = 11.0\n",
    "e = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_tr0 = np.zeros((Xtr0_mat100.shape[0], Xtr0_mat100.shape[0]))\n",
    "\n",
    "for i in tqdm(range(Xtr0_mat100.shape[0]), desc=\"Computing LA_tr0\"):\n",
    "    for j in range(i, Xtr0_mat100.shape[0]):\n",
    "        LA_tr0[i, j] = np.log(LA_Kernel(Xtr0['seq'][i], Xtr0['seq'][j], beta, d, e)) / beta\n",
    "        if i != j:\n",
    "            LA_tr0[j, i] = LA_tr0[i, j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Optimizer Function (Only Euler Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function using the precomputed kernel matrix K\n",
    "def loss(Y, m_t, alpha, lambd):\n",
    "    n = Y.shape[0]\n",
    "    loss = np.sum(np.log(1 + np.exp(-Y * m_t)))\n",
    "    return lambd * np.dot(alpha, m_t) / 2 + loss / n\n",
    "\n",
    "# Define the sigmoid function\n",
    "def sigmoid(u):\n",
    "    return 1/(1 + np.exp(-u))\n",
    "\n",
    "def W_func(Y, m_t):\n",
    "    n = Y.shape[0]\n",
    "    W = np.zeros(n)\n",
    "    W = sigmoid(m_t) * sigmoid(-m_t)\n",
    "    return np.diag(W)\n",
    "\n",
    "def P_func(Y, m_t):\n",
    "    n = Y.shape[0]\n",
    "    P = -sigmoid(-Y * m_t)\n",
    "    return np.diag(P)\n",
    "\n",
    "def z_func(Y, m_t):\n",
    "    return m_t + Y / sigmoid(Y * m_t)\n",
    "\n",
    "def quadratic_loss(K, Y, alpha_t, lambd, alpha):\n",
    "    n = K.shape[0]\n",
    "    m_t = np.dot(K, alpha_t)\n",
    "    W = W_func(Y, m_t)\n",
    "    P = P_func(Y, m_t)\n",
    "    z = z_func(Y, m_t)\n",
    "    return lambd * np.dot(alpha, np.dot(K, alpha)) + (K @ alpha - z).T @ W @ (K @ alpha - z) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve KLR by IRLS on the quadratic loss\n",
    "def IRLS(K, Y, alpha_0, lambd, tol=1e-6, max_iter=100, Y_test=None, K_test=None):\n",
    "    n = K.shape[0]\n",
    "    alpha_t = alpha_0.copy()\n",
    "    criterion = np.inf\n",
    "    for i in tqdm(range(max_iter), desc=\"IRLS Progress\"):\n",
    "        m_t = np.dot(K, alpha_t)\n",
    "        accuracy = np.mean(np.sign(m_t) == Y)\n",
    "        if Y_test is not None and K_test is not None:\n",
    "            test_accuracy = np.mean(np.sign(np.dot(K_test, alpha_t)) == Y_test)\n",
    "            print(f\"Iteration {i}: Loss - {loss(Y, m_t, alpha_t, lambd):.3f}, Convergence Criterion - : {criterion}, \\n Train Accuracy - {accuracy:.2f}, Test Accuracy - {test_accuracy}\")\n",
    "        else:\n",
    "            print(f\"Iteration {i}: Loss - {loss(Y, m_t, alpha_t, lambd):.3f}, Convergence Criterion - : {criterion}, Train Accuracy - {accuracy}\")\n",
    "        W_t = W_func(Y, m_t)\n",
    "        z_t = z_func(Y, m_t)\n",
    "        W_t_sqrt = np.sqrt(W_t)\n",
    "        A = (W_t_sqrt @ K @ W_t_sqrt + lambd * n * np.eye(n)) @ np.diag(1 / np.diag(W_t_sqrt))\n",
    "        B = W_t_sqrt @ z_t\n",
    "        alpha_new = np.linalg.solve(A, B)\n",
    "        criterion = np.linalg.norm(alpha_new - alpha_t)\n",
    "        if criterion < tol:\n",
    "            accuracy = np.mean(np.sign(np.dot(K, alpha_new)) == Y)\n",
    "            if Y_test is not None and K_test is not None:\n",
    "                test_accuracy = np.mean(np.sign(np.dot(K_test, alpha_new)) == Y_test)\n",
    "                print(f\"END : Iteration {i}: Loss - {loss(Y, m_t, alpha_t, lambd):.3f}, Convergence Criterion - : {criterion}, \\n Train Accuracy - {accuracy:.2f}, Test Accuracy - {test_accuracy}\")\n",
    "            else:\n",
    "                print(f\"END : Iteration {i}: Loss - {loss(Y, m_t, alpha_t, lambd):.3f}, Convergence Criterion - : {criterion}, Train Accuracy - {accuracy}\")\n",
    "            break\n",
    "        alpha_t = alpha_new\n",
    "        print(f'Alpha norm : {np.linalg.norm(alpha_t):.2f}')\n",
    "    return alpha_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Run Kernel Method on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the precomputed Smith-Waterman matrices\n",
    "SW_tr0 = np.load('SW_tr0.npy')\n",
    "SW_tr1 = np.load('SW_tr1.npy')\n",
    "SW_tr2 = np.load('SW_tr2.npy')\n",
    "\n",
    "# Function to shift the matrix to make it positive definite if the smallest eigenvalue is negative\n",
    "def make_positive_definite(SW_matrix):\n",
    "    eigenvalues, _ = np.linalg.eigh(SW_matrix)\n",
    "    min_eigenvalue = np.min(eigenvalues)\n",
    "    if min_eigenvalue < 0:\n",
    "        print(f\"Matrix is not positive definite, shifting by {-min_eigenvalue + 1e-6}\")\n",
    "        SW_matrix += np.eye(SW_matrix.shape[0]) * (-min_eigenvalue + 1e-6)\n",
    "    return SW_matrix\n",
    "\n",
    "# Apply the function to each dataset\n",
    "SW_tr0 = make_positive_definite(SW_tr0)\n",
    "SW_tr1 = make_positive_definite(SW_tr1)\n",
    "SW_tr2 = make_positive_definite(SW_tr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 1999\n",
    "s = 0.5 # Scaling factor for the Kernel matrices SW\n",
    "\n",
    "def split_kernel_matrix_random(K_exp, n_train):\n",
    "    indices = np.random.choice(K_exp.shape[0], n_train, replace=False)\n",
    "    K_train = K_exp[indices][:, indices]\n",
    "    K_test = np.delete(K_exp, indices, axis=0)[:, indices]\n",
    "    return K_train, K_test, indices\n",
    "\n",
    "# Split the datasets into training and testing sets\n",
    "K_tr0_train, K_tr0_test, indices0 = split_kernel_matrix_random(SW_tr0*s, n_train)\n",
    "K_tr1_train, K_tr1_test, indices1 = split_kernel_matrix_random(SW_tr1*s, n_train)\n",
    "K_tr2_train, K_tr2_test, indices2 = split_kernel_matrix_random(K_exp_tr2, n_train)\n",
    "\n",
    "Ytr0_train, Ytr0_test = Ytr0[indices0], np.delete(Ytr0, indices0)\n",
    "Ytr1_train, Ytr1_test = Ytr1[indices1], np.delete(Ytr1, indices1)\n",
    "Ytr2_train, Ytr2_test = Ytr2[indices2], np.delete(Ytr2, indices2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd_0 = 0.2\n",
    "alpha_0_0 = np.zeros(K_tr0_train.shape[0])\n",
    "# Run the IRLS algorithm with the new initialization for the first dataset\n",
    "alpha_0_0 = IRLS(K_tr0_train, Ytr0_train, alpha_0_0, lambd_0, tol=1e-5, max_iter=10, \n",
    "                 Y_test=Ytr0_test, K_test=K_tr0_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd_1 = 0.1\n",
    "alpha_0_1 = np.zeros(K_tr1_train.shape[0])\n",
    "# Run the IRLS algorithm with the new initialization for the second dataset\n",
    "alpha_0_1 = IRLS(K_tr1_train, Ytr1_train, alpha_0_1, lambd_1, tol=1e-5, max_iter=10, \n",
    "                 Y_test=Ytr1_test, K_test=K_tr1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd_2 = 0.0005\n",
    "alpha_0_2 = np.zeros(K_tr2_train.shape[0])\n",
    "# Run the IRLS algorithm with the new initialization for the third dataset\n",
    "alpha_0_2 = IRLS(K_tr2_train, Ytr2_train, alpha_0_2, lambd_2, tol=1e-5, max_iter=10, \n",
    "                 Y_test=Ytr2_test, K_test=K_tr2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(K_train, K_test, Y_train, Y_test, alpha):\n",
    "    train_predictions = np.sign(K_train @ alpha)\n",
    "    train_accuracy = np.mean(train_predictions == Y_train) * 100\n",
    "    print(f\"Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    test_predictions = np.sign(K_test @ alpha)\n",
    "    test_accuracy = np.mean(test_predictions == Y_test) * 100\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    print(f\"Alpha's norm: {np.linalg.norm(alpha):.2f}\")\n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "# Calculate accuracy for the first dataset\n",
    "print(\"-----First dataset-----\")\n",
    "_, a0 = calculate_accuracy(K_tr0_train, K_tr0_test, Ytr0_train, Ytr0_test, alpha_0_0)\n",
    "# Calculate accuracy for the second dataset\n",
    "print(\"-----Second dataset-----\")\n",
    "_, a1 = calculate_accuracy(K_tr1_train, K_tr1_test, Ytr1_train, Ytr1_test, alpha_0_1)\n",
    "# Calculate accuracy for the third dataset\n",
    "print(\"-----Third dataset-----\")\n",
    "_, a2 = calculate_accuracy(K_tr2_train, K_tr2_test, Ytr2_train, Ytr2_test, alpha_0_2)\n",
    "\n",
    "# Mean accuracy\n",
    "mean_accuracy = (a0 + a1 + a2) / 3\n",
    "print(f\"Mean accuracy: {mean_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Apply Kernel Predictor on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrix representation of the sequences\n",
    "Xte0_mat100 = pd.read_csv('data/Xte0_mat100.csv', header=None, sep=' ').values\n",
    "Xte1_mat100 = pd.read_csv('data/Xte1_mat100.csv', header=None, sep=' ').values\n",
    "Xte2_mat100 = pd.read_csv('data/Xte2_mat100.csv', header=None, sep=' ').values\n",
    "Xte0 = pd.read_csv('data/Xte0.csv', index_col=0)\n",
    "Xte1 = pd.read_csv('data/Xte1.csv', index_col=0)\n",
    "Xte2 = pd.read_csv('data/Xte2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Kernels for the test set\n",
    "SW_te0 = compute_sw_matrix(Xte0, Xtr0.iloc[:n_train], sm.SmithWaterman())\n",
    "SW_te1 = compute_sw_matrix(Xte1, Xtr1.iloc[:n_train], sm.SmithWaterman())\n",
    "K_dist_te2 = compute_distance_matrix(Xte2_mat100, Xtr2_mat100[:n_train,:])\n",
    "K_exp_te2 = exp_kernel(K_dist_te2, sigma=0.15)\n",
    "\n",
    "K_te0 = SW_te0[:,:n_train] * s\n",
    "K_te1 = SW_te1[:,:n_train] * s\n",
    "K_te2 = K_exp_te2[:,:n_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "Yte0 = np.sign(K_te0 @ alpha_0_0)\n",
    "Yte1 = np.sign(K_te1 @ alpha_0_1)\n",
    "Yte2 = np.sign(K_te2 @ alpha_0_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate and add Id column\n",
    "Yte = np.concatenate([Yte0, Yte1, Yte2])\n",
    "Yte = (Yte + 1) // 2\n",
    "Yte = pd.DataFrame(data=Yte, columns=['Bound'], dtype='int64')\n",
    "Yte.insert(0, 'Id', Yte.index)\n",
    "# Save the predictions\n",
    "Yte.to_csv('Yte_3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
