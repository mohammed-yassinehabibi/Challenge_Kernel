{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import py_stringmatching as sm\n",
    "import osqp\n",
    "from collections import Counter\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "from Local_packages.kernels import compute_kernel_matrix, gaussian_kernel, normalize\n",
    "from Local_packages.run import KernelMethod, KernelMethodBias\n",
    "from Local_packages.optimizer import KLR_solver, SVM_solver, SVM_solver_with_bias\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "Xtr0 = pd.read_csv('data/Xtr0.csv', index_col=0)\n",
    "Xtr1 = pd.read_csv('data/Xtr1.csv', index_col=0)\n",
    "Xtr2 = pd.read_csv('data/Xtr2.csv',  index_col=0)\n",
    "Xte0 = pd.read_csv('data/Xte0.csv', index_col=0)\n",
    "Xte1 = pd.read_csv('data/Xte1.csv', index_col=0)\n",
    "Xte2 = pd.read_csv('data/Xte2.csv', index_col=0)\n",
    "\n",
    "Xtr0_Xte0 = pd.concat([Xtr0, Xte0], ignore_index=True)\n",
    "Xtr1_Xte1 = pd.concat([Xtr1, Xte1], ignore_index=True)\n",
    "Xtr2_Xte2 = pd.concat([Xtr2, Xte2], ignore_index=True)\n",
    "\n",
    "# Load the labels\n",
    "Ytr0 = pd.read_csv('data/Ytr0.csv', index_col=0)\n",
    "Ytr1 = pd.read_csv('data/Ytr1.csv', index_col=0)\n",
    "Ytr2 = pd.read_csv('data/Ytr2.csv', index_col=0)\n",
    "# Convert the labels to -1, 1\n",
    "Ytr0 = 2*Ytr0['Bound'].values - 1\n",
    "Ytr1 = 2*Ytr1['Bound'].values - 1\n",
    "Ytr2 = 2*Ytr2['Bound'].values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrix representation of the sequences\n",
    "Xtr0_mat100 = pd.read_csv('data/Xtr0_mat100.csv', header=None, sep=' ').values\n",
    "Xtr1_mat100 = pd.read_csv('data/Xtr1_mat100.csv', header=None, sep=' ').values\n",
    "Xtr2_mat100 = pd.read_csv('data/Xtr2_mat100.csv', header=None, sep=' ').values\n",
    "Xte0_mat100 = pd.read_csv('data/Xte0_mat100.csv', header=None, sep=' ').values\n",
    "Xte1_mat100 = pd.read_csv('data/Xte1_mat100.csv', header=None, sep=' ').values\n",
    "Xte2_mat100 = pd.read_csv('data/Xte2_mat100.csv', header=None, sep=' ').values\n",
    "\n",
    "Xtr0_Xte0_mat100 = np.concatenate([Xtr0_mat100, Xte0_mat100], axis=0)\n",
    "Xtr1_Xte1_mat100 = np.concatenate([Xtr1_mat100, Xte1_mat100], axis=0)\n",
    "Xtr2_Xte2_mat100 = np.concatenate([Xtr2_mat100, Xte2_mat100], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Compute Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gkm_kernel(seq1, seq2, k=3, gap=1):\n",
    "    \"\"\"Compute the gapped k-mer kernel between two sequences.\"\"\"\n",
    "    def extract_gapped_kmers(seq, k, gap):\n",
    "        kmers = set()\n",
    "        for i in range(len(seq) - (k + gap - 1)):\n",
    "            kmers.add(seq[i] + seq[i + gap + 1 : i + gap + k])  # gapped k-mer\n",
    "        return kmers\n",
    "    \n",
    "    kmers1 = extract_gapped_kmers(seq1, k, gap)\n",
    "    kmers2 = extract_gapped_kmers(seq2, k, gap)\n",
    "    \n",
    "    return len(kmers1.intersection(kmers2))  # Kernel similarity score\n",
    "\n",
    "def compute_row(i, X_left, X_right, k, gap):\n",
    "    \"\"\"Compute one row of the kernel matrix.\"\"\"\n",
    "    return [gkm_kernel(X_left[i], X_right[j], k, gap) for j in range(len(X_right))]\n",
    "\n",
    "def compute_gkm_kernel_matrix(X_left, X_right, k=3, gap=1, n_jobs=-1):\n",
    "    \"\"\"Compute the gapped k-mer kernel matrix using parallelization.\"\"\"\n",
    "    n_samples_left = len(X_left)\n",
    "    \n",
    "    kernel_matrix = Parallel(n_jobs=n_jobs)(\n",
    "      delayed(compute_row)(i, X_left, X_right, k, gap) for i in tqdm(range(n_samples_left))\n",
    "    )\n",
    "    \n",
    "    return np.array(kernel_matrix)\n",
    "\n",
    "# Example usage\n",
    "X_left = Xtr0_Xte0['seq'].to_list()\n",
    "X_right = Xtr0_Xte0['seq'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:42<00:00, 71.11it/s]\n",
      "100%|██████████| 3000/3000 [00:45<00:00, 65.77it/s]\n",
      "100%|██████████| 3000/3000 [00:48<00:00, 62.21it/s]\n"
     ]
    }
   ],
   "source": [
    "kernel_matrix_0 = compute_gkm_kernel_matrix(Xtr0_Xte0['seq'].to_list(), Xtr0_Xte0['seq'].to_list(), k=8, gap=5)\n",
    "K_0 = normalize(kernel_matrix_0)\n",
    "kernel_matrix_1 = compute_gkm_kernel_matrix(Xtr1_Xte1['seq'].to_list(), Xtr1_Xte1['seq'].to_list(), k=8, gap=5)\n",
    "K_1 = normalize(kernel_matrix_1)\n",
    "kernel_matrix_2 = compute_gkm_kernel_matrix(Xtr2_Xte2['seq'].to_list(), Xtr2_Xte2['seq'].to_list(), k=8, gap=5)\n",
    "K_2 = normalize(kernel_matrix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'mismatch'\n",
    "\n",
    "#Gaussian Kernel - On the matrix representation of the sequences\n",
    "if kernel=='exp':\n",
    "    args = {'sigma': 0.13}\n",
    "#Smith-Waterman Local Alignment Score\n",
    "elif kernel=='sw':\n",
    "    args = {'sw': sm.SmithWaterman()}\n",
    "#Spectrum Kernel\n",
    "elif kernel=='spect':\n",
    "    args = {'k': 5}\n",
    "#Mismatch Kernel\n",
    "elif kernel=='mismatch':\n",
    "    args = {'k': 5, 'm': 0}\n",
    "elif kernel=='mis_sub':\n",
    "    args = {'k': 5, 'm': 3}\n",
    "#LA Kernel\n",
    "elif kernel=='LA':\n",
    "    args = {'beta': 0.5, 'd': 11, 'e': 1}\n",
    "elif kernel=='LA_gpu':\n",
    "    args = {'beta': 0.5, 'd': 1, 'e': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature vectors: 100%|██████████| 3000/3000 [00:00<00:00, 9854.85it/s]\n",
      "Collecting k-mers: 100%|██████████| 3000/3000 [00:00<00:00, 3746.87it/s]\n",
      "Building sparse matrix entries: 100%|██████████| 3000/3000 [00:01<00:00, 2864.62it/s]\n",
      "Computing feature vectors: 100%|██████████| 3000/3000 [00:00<00:00, 9603.00it/s]\n",
      "Collecting k-mers: 100%|██████████| 3000/3000 [00:00<00:00, 4479.12it/s]\n",
      "Building sparse matrix entries: 100%|██████████| 3000/3000 [00:00<00:00, 3462.01it/s]\n",
      "Computing feature vectors: 100%|██████████| 3000/3000 [00:00<00:00, 11092.23it/s]\n",
      "Collecting k-mers: 100%|██████████| 3000/3000 [00:00<00:00, 5277.98it/s]\n",
      "Building sparse matrix entries: 100%|██████████| 3000/3000 [00:00<00:00, 3571.70it/s]\n"
     ]
    }
   ],
   "source": [
    "K_0 = compute_kernel_matrix(Xtr0_Xte0, Xtr0_Xte0, kernel, **args)\n",
    "K_1 = compute_kernel_matrix(Xtr1_Xte1, Xtr1_Xte1, kernel, **args)\n",
    "K_2 = compute_kernel_matrix(Xtr2_Xte2, Xtr2_Xte2, kernel, **args)\n",
    "\n",
    "#K_0 = compute_kernel_matrix(Xtr0_Xte0, Xtr0_Xte0, kernel, **args)\n",
    "#K_1 = compute_kernel_matrix(Xtr1_Xte1, Xtr1_Xte1, kernel, **args)\n",
    "#K_2 = compute_kernel_matrix(Xtr2_Xte2, Xtr2_Xte2, kernel, **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_0 = normalize(K_0)\n",
    "K_1 = normalize(K_1)\n",
    "K_2 = normalize(K_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('features/K_0_mismatch_5-0.npy', K_0)\n",
    "np.save('features/K_1_mismatch_5-0.npy', K_1)\n",
    "np.save('features/K_2_mismatch_5-0.npy', K_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute only the diagonal of the kernel matrix for the test set\n",
    "def compute_kernel_for_row(i, Xte, kernel, args):\n",
    "    return compute_kernel_matrix(Xte.iloc[[i]], Xte.iloc[[i]], kernel, **args)\n",
    "\n",
    "#K_te_0 = np.concatenate(Parallel(n_jobs=-1)(delayed(compute_kernel_for_row)(i, Xte0, kernel, args) for i in tqdm(range(len(Xte0)))), axis=0)\n",
    "K_te_1 = np.concatenate(Parallel(n_jobs=-1)(delayed(compute_kernel_for_row)(i, Xte1, kernel, args) for i in tqdm(range(len(Xte1)))), axis=0)\n",
    "K_te_2 = np.concatenate(Parallel(n_jobs=-1)(delayed(compute_kernel_for_row)(i, Xte2, kernel, args) for i in tqdm(range(len(Xte2)))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('features/K_0_tr_mismatch_10-2.npy', K_0)\n",
    "np.save('features/K_1_te_diag_mismatch_10-2.npy', K_te_1)\n",
    "np.save('features/K_2_te_diag_mismatch_10-2.npy', K_te_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Merge sub-kernels into one kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the kernel matrices on Xtr x Xtr\n",
    "K_tr_0 = np.load('features/K_0_tr_mismatch_10-2.npy')\n",
    "K_tr_1 = np.load('features/K_1_tr_mismatch_10-2.npy')\n",
    "K_tr_2 = np.load('features/K_2_tr_mismatch_10-2.npy')\n",
    "# Load the kernel vector on {Xte_i, Xte_i}_i\n",
    "K_te_0 = np.load('features/K_0_te_diag_mismatch_10-2.npy')\n",
    "K_te_1 = np.load('features/K_1_te_diag_mismatch_10-2.npy')\n",
    "K_te_2 = np.load('features/K_2_te_diag_mismatch_10-2.npy')\n",
    "# Concatenate the kernel vector on {Xtr_i, Xte_i}_i and {Xte_i, Xte_i}_i to get the diagonal of the whole kernel matrix K \n",
    "K_diag_0 = np.concatenate([np.diag(K_tr_0),K_te_0.flatten()], axis=0)\n",
    "K_diag_1 = np.concatenate([np.diag(K_tr_1),K_te_1.flatten()], axis=0)\n",
    "K_diag_2 = np.concatenate([np.diag(K_tr_2),K_te_2.flatten()], axis=0)\n",
    "# Load the kernel matrices on Xte x Xtr\n",
    "K_tr_te_0 = np.load('features/K_0_te_mismatch_10-2.npy')\n",
    "K_tr_te_1 = np.load('features/K_1_te_mismatch_10-2.npy')\n",
    "K_tr_te_2 = np.load('features/K_2_te_mismatch_10-2.npy')\n",
    "# Concatenate the kernel matrices on Xtr x Xtr and Xte x Xtr to get the whole kernel matrix K on (Xtr U Xte) x Xtr\n",
    "K_0 = np.concatenate([K_tr_0, K_tr_te_0], axis=0)\n",
    "K_1 = np.concatenate([K_tr_1, K_tr_te_1], axis=0)\n",
    "K_2 = np.concatenate([K_tr_2, K_tr_te_2], axis=0)\n",
    "# Normalize the kernel matrix K\n",
    "D_0 = np.diag(1/np.sqrt(K_diag_0))\n",
    "D_1 = np.diag(1/np.sqrt(K_diag_1))\n",
    "D_2 = np.diag(1/np.sqrt(K_diag_2))\n",
    "K_0 = np.dot(np.dot(D_0, K_0), D_0[:K_tr_0.shape[0]][:,:K_tr_0.shape[0]]) \n",
    "K_1 = np.dot(np.dot(D_1, K_1), D_1[:K_tr_0.shape[0]][:,:K_tr_0.shape[0]]) \n",
    "K_2 = np.dot(np.dot(D_2, K_2), D_2[:K_tr_0.shape[0]][:,:K_tr_0.shape[0]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('features/K_0_mismatch_10-2.npy', K_0)\n",
    "np.save('features/K_1_mismatch_10-2.npy', K_1)\n",
    "np.save('features/K_2_mismatch_10-2.npy', K_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Load kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_versions = ['5-1', '5-2', '6-1', '6-2', '7-1', '7-2', '8-1', '8-2', '9-1', '9-2', '10-2', '5-0', '6-0', '7-0', '8-0', '9-0']\n",
    "K_0_dict, K_1_dict, K_2_dict = {}, {}, {}\n",
    "\n",
    "for version in kernel_versions:\n",
    "    K_0_dict[version] = np.load(f'features/K_0_mismatch_{version}.npy')\n",
    "    K_1_dict[version] = np.load(f'features/K_1_mismatch_{version}.npy')\n",
    "    K_2_dict[version] = np.load(f'features/K_2_mismatch_{version}.npy')\n",
    "\n",
    "# Load the additional kernel matrix\n",
    "#K_0_dict['exp-0_1'] = np.load('features/K_0_exp-0_1.npy')\n",
    "#K_1_dict['exp-0_1'] = np.load('features/K_1_exp-0_1.npy')\n",
    "#K_2_dict['exp-0_1'] = np.load('features/K_2_exp-0_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50571245 0.68502593 0.454753 0.5665562 0.4964234\n",
      "0.006316263 0.045187116 0.0 0.034760356 0.0020040865\n"
     ]
    }
   ],
   "source": [
    "print(K_0_dict['8-1'][1:,0].max(), K_0_dict['8-2'][1:,0].max(), K_0_dict['9-1'][1:,0].max(), K_0_dict['9-2'][1:,0].max(), K_0_dict['10-2'][1:,0].max())\n",
    "print(K_0_dict['8-1'][1:,0].min(), K_1_dict['8-2'][1:,0].min(), K_1_dict['9-1'][1:,0].min(), K_0_dict['9-2'][1:,0].min(), K_1_dict['10-2'][1:,0].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Combine kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_versions = ['9-2', '10-2']\n",
    "K_0_prod_2 = np.prod([K_0_dict[version][:,:2000] for version in kernel_versions], axis=0)\n",
    "K_1_prod_2 = np.prod([K_1_dict[version][:,:2000] for version in kernel_versions], axis=0)\n",
    "K_2_prod_2 = np.prod([K_2_dict[version][:,:2000] for version in kernel_versions], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exponential kernel from concatenation of kernels\n",
    "#Concatenate Kernels\n",
    "kernel_versions = ['5-2', '6-2', '9-2', '8-2']\n",
    "K_0_concat = np.stack([K_0_dict[version][:, :2000] for version in kernel_versions], axis=-1)\n",
    "K_1_concat = np.stack([K_1_dict[version][:, :2000] for version in kernel_versions], axis=-1)\n",
    "K_2_concat = np.stack([K_2_dict[version][:, :2000] for version in kernel_versions], axis=-1)\n",
    "#Take norm Kernel\n",
    "K_0_exp = np.exp(np.linalg.norm(K_0_concat, axis=-1))\n",
    "K_1_exp = np.exp(np.linalg.norm(K_1_concat, axis=-1))\n",
    "K_2_exp = np.exp(np.linalg.norm(K_2_concat, axis=-1))\n",
    "K_0_norm = np.linalg.norm(K_0_concat, axis=-1)\n",
    "K_1_norm = np.linalg.norm(K_1_concat, axis=-1)\n",
    "K_2_norm = np.linalg.norm(K_2_concat, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal kernel (gives 100% accuracy on the training set)\n",
    "K_0_opt = ((Ytr0+1)/2)[:,None]*((Ytr0+1)/2)[None,:]\n",
    "K_1_opt = ((Ytr1+1)/2)[:,None]*((Ytr1+1)/2)[None,:]\n",
    "K_2_opt = ((Ytr2+1)/2)[:,None]*((Ytr2+1)/2)[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment(K_a, K_a_opt):\n",
    "    return np.sum(K_a[:2000]*K_a_opt)/np.sqrt(np.sum(K_a[:2000]**2)*np.sum(K_a_opt**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_versions = ['5-1', '5-2', '6-1', '6-2', '7-1', '7-2', '8-1', '8-2', '9-1', '9-2']\n",
    "for kernel_version in kernel_versions:\n",
    "    print(alignment(K_2_dict[kernel_version][:,:2000],K_2_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dataset 0\n",
    "w_0_prod_1 = alignment(K_0_prod_1, K_0_opt)\n",
    "w_0_prod_2 = alignment(K_0_prod_2, K_0_opt)\n",
    "w_0 = w_0_prod_1 + w_0_prod_2\n",
    "K_0 = K_0_prod_1**(w_0_prod_1/w_0)*K_0_prod_2**(w_0_prod_2/w_0) + 1\n",
    "\n",
    "# For dataset 1\n",
    "w_1_prod_1 = alignment(K_1_prod_1, K_1_opt)\n",
    "w_1_prod_2 = alignment(K_1_prod_2, K_1_opt)\n",
    "w_1 = w_1_prod_1 + w_1_prod_2\n",
    "K_1 = K_1_prod_1**(w_1_prod_1/w_1)*K_1_prod_2**(w_1_prod_2/w_1) + 1\n",
    "\n",
    "# For dataset 2\n",
    "w_2_prod_1 = alignment(K_2_prod_1, K_2_opt)\n",
    "w_2_prod_2 = alignment(K_2_prod_2, K_2_opt)\n",
    "w_2 = w_2_prod_1 + w_2_prod_2\n",
    "K_2 = K_2_prod_1**(w_2_prod_1/w_2)*K_2_prod_2**(w_2_prod_2/w_2) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Local Alignment Kernel  : <span style=\"color:green\">TODO / Time Complexity too high + value too high</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Local Alignment Kernel defined as:\n",
    "$$K_{LA}^{(\\beta)}(x,y) = \\sum_{\\pi\\in\\Pi(x,y)} s_{S,g}(\\pi)$$\n",
    "\n",
    "is symmetric positive definite.\n",
    "\n",
    "We assume an affine gap penalty:\n",
    "$$\\left\\{\\begin{aligned}\n",
    "&g(0) = 0 \\\\\n",
    "&g(n) = d + e(n-1) \\quad \\text{for } n>0\n",
    "\\end{aligned}\\right.$$\n",
    "\n",
    "where $l(\\pi)$ is the length of the alignment $\\pi$.\n",
    "\n",
    "We use the formula for the Local Alignment Kernel:\n",
    "$$K_{LA}^{(\\beta)}(x,y) = 1 + X_2(|x|,|y|)+ Y_2(|x|,|y|) + M(|x|,|y|)$$ \n",
    "where $X_2$, $Y_2$ and $M$ are defined recursively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Run Kernel Method on Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Dataset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3682092, 3.079341)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_0_concat = np.stack([K_0_dict[version][:, :2000] for version in ['10-2', '5-0', '9-2']], axis=0)\n",
    "K_0_norm = np.exp(np.linalg.norm(K_0_concat, axis=0)-1)\n",
    "K_0 = K_0_norm+1\n",
    "K_0.min(), K_0.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.675)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method\n",
    "#K_0 = K_0_dict['10-2'][:, :2000]**1*K_0_dict['5-0'][:, :2000]**1+K_0_dict['10-2'][:, :2000]**2\n",
    "lambd = 1.1e-1\n",
    "#method_0 = KernelMethod((K_0)[:2000, :2000], Ytr0, solver=SVM_solver)\n",
    "method_0 = KernelMethodBias(K_0[:2000, :2000], Ytr0, solver=SVM_solver_with_bias)\n",
    "method_0.lambd = lambd\n",
    "method_0.train_test_split(test_size=0.02, random_state=12)\n",
    "method_0.fit()\n",
    "method_0.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 3103.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.649\n",
      "Min Accuracy: 0.615 Max Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_0.validate(test_size=0.1, n_splits=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BEST AVERAGE ACCURACY : 64.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_0_concat = np.stack([K_0_dict[version][:, :2000] for version in ['8-2', '9-2', '5-1']], axis=-1)\n",
    "K_0_norm = np.linalg.norm(K_0_concat, axis=-1)\n",
    "K_0 = K_0_norm+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_1 = K_1_dict['9-2'][:2000,:2000]**2 + K_1_dict['6-1'][:2000,:2000]**2+K_1_dict['5-1'][:2000,:2000]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76, 0.81, 0.705, 0.755, 0.78, 0.835, 0.81, 0.82, 0.78, 0.795, 0.785\n"
     ]
    }
   ],
   "source": [
    "K_1 = K_1_dict['9-2'][:,:2000]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_1 = (K_1_dict['9-2'][:,:2000]*K_1_dict['10-2'][:,:2000]+K_1_dict['6-1'][:,:2000]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambd_1 = 1e-1\n",
    "K_1 = K_1_dict['9-2'][:,:2000]**2\n",
    "#method_1 = KernelMethod((K_1)[:2000, :2000], Ytr1, lambd=lambd_1, solver=SVM_solver)\n",
    "method_1 = KernelMethodBias(K_1[:2000, :2000], Ytr1,lambd=lambd_1, solver=SVM_solver_with_bias)\n",
    "method_1.train_test_split(test_size=0.02, random_state=12)\n",
    "method_1.fit()\n",
    "method_1.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76, 0.815, 0.705, 0.755, 0.78, 0.835, 0.81, 0.815, 0.785, 0.795, 0.7855000000000001\n"
     ]
    }
   ],
   "source": [
    "lambd_1 = 1e-1\n",
    "K_1 = K_1_dict['9-2'][:,:2000]**2\n",
    "#method_1 = KernelMethod((K_1)[:2000, :2000], Ytr1, lambd=lambd_1, solver=SVM_solver)\n",
    "method_1 = KernelMethodBias(K_1[:2000, :2000], Ytr1,lambd=lambd_1, solver=SVM_solver_with_bias)\n",
    "seeds = [1, 10, 42, 50, 100, 12, 15, 20, 25, 30]\n",
    "val = []\n",
    "for seed in seeds:\n",
    "    method_1.train_test_split(test_size=0.1, random_state=seed)\n",
    "    method_1.fit()\n",
    "    val.append(method_1.evaluate()[1])\n",
    "    print(val[-1], end=', ')\n",
    "print(np.mean(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.7912499999999999\n",
      "Min Accuracy: 0.6 Max Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_1.validate(test_size=0.02, n_splits=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:22<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.8032499999999999\n",
      "Min Accuracy: 0.6 Max Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_1.validate(test_size=0.02, n_splits=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_2_s = []\n",
    "K_2_s.append(K_2_dict['9-1'][:,:2000]*K_2_dict['9-2'][:,:2000]**2+1)\n",
    "K_2_s.append(K_2_dict['9-1'][:,:2000]*K_2_dict['9-2'][:,:2000]**2+K_2_dict['5-0'][:,:2000]**3+1)\n",
    "K_2_s.append(K_2_dict['5-0'][:,:2000]**3+1)\n",
    "K_2_s.append(K_2_dict['10-2'][:,:2000]**1.5+1)\n",
    "K_2_s.append(K_2_dict['7-1'][:,:2000]**2+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_2 = K_2_dict['10-2'][:,:2000]**2.5+1\n",
    "#K_2 = normalize(K_2[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69, 0.68, 0.67, 0.68, 0.71, 0.665, 0.66, 0.685, 0.635, 0.765, 0.6839999999999999\n"
     ]
    }
   ],
   "source": [
    "K_2 = K_2_dict['9-1'][:,:2000]*K_2_dict['9-2'][:,:2000]**2+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.705, 0.68, 0.69, 0.67, 0.74, 0.65, 0.655, 0.66, 0.62, 0.765, 0.6835\n"
     ]
    }
   ],
   "source": [
    "K_2 = K_2_dict['9-1'][:,:2000]*K_2_dict['9-2'][:,:2000]**2+K_2_dict['5-0'][:,:2000]**3+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.675, 0.67, 0.695, 0.68, 0.72, 0.655, 0.665, 0.66, 0.655, 0.74, 0.6815\n"
     ]
    }
   ],
   "source": [
    "K_2 = K_2_dict['5-0'][:,:2000]**3+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715, 0.665, 0.7, 0.685, 0.72, 0.685, 0.67, 0.665, 0.64, 0.785, 0.693\n"
     ]
    }
   ],
   "source": [
    "K_2 = K_2_dict['10-2'][:,:2000]**1.5+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68, 0.675, 0.68, 0.675, 0.72, 0.665, 0.665, 0.675, 0.63, 0.78, 0.6845000000000001\n"
     ]
    }
   ],
   "source": [
    "K_2 = K_2_dict['10-2'][:,:2000]**2+1\n",
    "lambd_2 = 1e-1\n",
    "#method_2 = KernelMethod((K_2)[:2000, :2000], Ytr2, lambd=lambd_2, solver=SVM_solver)\n",
    "method_2 = KernelMethodBias(K_2[:2000, :2000], Ytr2,lambd=lambd_2, solver=SVM_solver_with_bias)\n",
    "seeds = [1, 10, 42, 50, 100, 12, 15, 20, 25, 30]\n",
    "val = []\n",
    "for seed in seeds:\n",
    "    method_2.train_test_split(test_size=0.1, random_state=seed)\n",
    "    method_2.fit()\n",
    "    val.append(method_2.evaluate()[1])\n",
    "    print(val[-1], end=', ')\n",
    "print(np.mean(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.7)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_2 = K_2_dict['10-2'][:,:2000]**1.5\n",
    "lambd_2 = 1e-1\n",
    "#method_2 = KernelMethod((K_2)[:2000, :2000], Ytr2, lambd=lambd_2, solver=SVM_solver)\n",
    "method_2 = KernelMethodBias(K_2[:2000, :2000], Ytr2,lambd=lambd_2, solver=SVM_solver_with_bias)\n",
    "method_2.train_test_split(test_size=0.02, random_state=12)\n",
    "method_2.fit()\n",
    "method_2.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:18<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.6835\n",
      "Min Accuracy: 0.525 Max Accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_2.validate(test_size=0.02, n_splits=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:20<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.6900000000000002\n",
      "Min Accuracy: 0.475 Max Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_2.validate(test_size=0.02, n_splits=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.6999999999999998\n",
      "Min Accuracy: 0.5 Max Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = method_2.validate(test_size=0.02, n_splits=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BEST AVERAGE ACCURACY : 69.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.69575\n",
      "Min Accuracy: 0.64 Max Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "test = K_2_dict['9-1'][:,:2000]*K_2_dict['9-2'][:,:2000]**2+1 # lambd_2 = 1e-4 ?\n",
    "average_accuracy = method_2.validate(test_size=0.1, n_splits=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Apply Kernel Predictor on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_labels(K, method):\n",
    "    K_te = K\n",
    "    alpha = method.alpha\n",
    "    b = method.b\n",
    "    # Predictions\n",
    "    Yte0 = np.sign(np.dot(K_te, alpha * method.Y[method.train_indices]) + b)\n",
    "    return Yte0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte_file_name = 'Yte_mismatches_bias_SVM_2.csv'\n",
    "\n",
    "Yte0 = predict_test_labels(K_0[2000:][:, method_0.train_indices], method_0)\n",
    "Yte1 = predict_test_labels(K_1[2000:][:,method_1.train_indices], method_1)\n",
    "Yte2 = predict_test_labels(K_2[2000:][:,method_2.train_indices], method_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate and add Id column\n",
    "Yte = np.concatenate([Yte0, Yte1, Yte2])\n",
    "Yte = pd.DataFrame(data=(Yte + 1) // 2, columns=['Bound'], dtype='int64')\n",
    "Yte.insert(0, 'Id', Yte.index)\n",
    "\n",
    "# Save the predictions\n",
    "Yte.to_csv(Yte_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Local_packages.run import KernelMethod\n",
    "from Local_packages.optimizer import SVM_solver\n",
    "\n",
    "\n",
    "# Load the labels\n",
    "Ytr0 = pd.read_csv('data/Ytr0.csv', index_col=0)\n",
    "Ytr1 = pd.read_csv('data/Ytr1.csv', index_col=0)\n",
    "Ytr2 = pd.read_csv('data/Ytr2.csv', index_col=0)\n",
    "# Convert the labels to -1, 1\n",
    "Ytr0 = 2*Ytr0['Bound'].values - 1\n",
    "Ytr1 = 2*Ytr1['Bound'].values - 1\n",
    "Ytr2 = 2*Ytr2['Bound'].values - 1\n",
    "\n",
    "kernel_versions = ['5-1', '5-2', '6-1', '6-2', '7-1', '7-2', '8-1', '8-2', '9-1', '9-2', '10-2']\n",
    "K_0_dict, K_1_dict, K_2_dict = {}, {}, {}\n",
    "\n",
    "for version in kernel_versions:\n",
    "    K_0_dict[version] = np.load(f'features/K_0_mismatch_{version}.npy')\n",
    "    K_1_dict[version] = np.load(f'features/K_1_mismatch_{version}.npy')\n",
    "    K_2_dict[version] = np.load(f'features/K_2_mismatch_{version}.npy')\n",
    "\n",
    "### DATASET 1 ###\n",
    "K_0_concat = np.stack([K_0_dict[version][:, :2000] for version in ['8-2', '9-2', '5-1']], axis=0)\n",
    "K_0_norm = np.exp(np.linalg.norm(K_0_concat, axis=0)-1)\n",
    "K_0 = K_0_norm+1\n",
    "\n",
    "lambd_0 = 1e-5\n",
    "method_0 = KernelMethod(K_0[:2000, :2000], Ytr0, lambd=lambd_0, solver=SVM_solver)\n",
    "method_0.train_test_split(test_size=0.1, random_state=42)\n",
    "method_0.fit()\n",
    "\n",
    "### DATASET 2 ###\n",
    "K_1 = K_1_dict['9-2'][:,:2000]**2\n",
    "\n",
    "lambd_1 = 1e-4\n",
    "method_1 = KernelMethod((K_1+1)[:2000], Ytr1, lambd=lambd_1, solver=SVM_solver)\n",
    "method_1.train_test_split(test_size=0.1, random_state=10)\n",
    "method_1.fit()\n",
    "\n",
    "### DATASET 3 ###\n",
    "K_2 = K_2_dict['9-1'][:,:2000]*K_2_dict['9-2'][:,:2000]**2+1\n",
    "\n",
    "lambd_2 = 2e-4\n",
    "method_2 = KernelMethod((K_2)[:2000, :2000], Ytr2, lambd=lambd_2, solver=SVM_solver)\n",
    "method_2.train_test_split(test_size=0.1, random_state=10)\n",
    "method_2.fit()\n",
    "\n",
    "### Predictions ###\n",
    "def predict_test_labels(K, method):\n",
    "    K_te = K\n",
    "    alpha = method.alpha\n",
    "    Yte0 = np.sign(K_te @ alpha)\n",
    "    return Yte0\n",
    "\n",
    "Yte0 = predict_test_labels(K_0[2000:][:, method_0.train_indices], method_0)\n",
    "Yte1 = predict_test_labels(K_1[2000:][:,method_1.train_indices], method_1)\n",
    "Yte2 = predict_test_labels(K_2[2000:][:,method_2.train_indices], method_2)\n",
    "\n",
    "Yte_file_name = 'Yte.csv'\n",
    "\n",
    "# Concatenate and add Id column\n",
    "Yte = np.concatenate([Yte0, Yte1, Yte2])\n",
    "Yte = pd.DataFrame(data=(Yte + 1) // 2, columns=['Bound'], dtype='int64')\n",
    "Yte.insert(0, 'Id', Yte.index)\n",
    "\n",
    "# Save the predictions\n",
    "Yte.to_csv(Yte_file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
